{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6752e984",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81560c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.39.8)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: PyMuPDF in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.26.3)\n",
      "Collecting langchain-chroma\n",
      "  Downloading langchain_chroma-0.2.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: langchain-openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.3.28)\n",
      "Requirement already satisfied: langchain in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-community in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.3.27)\n",
      "Requirement already satisfied: chromadb in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.0.15)\n",
      "Requirement already satisfied: rank_bm25 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.2.2)\n",
      "Requirement already satisfied: botocore<1.40.0,>=1.39.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from boto3) (1.39.8)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from boto3) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/alistermarcdomilies/Library/Python/3.11/lib/python/site-packages (from botocore<1.40.0,>=1.39.8->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from botocore<1.40.0,>=1.39.8->boto3) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alistermarcdomilies/Library/Python/3.11/lib/python/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.40.0,>=1.39.8->boto3) (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: langchain-core>=0.3.60 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-chroma) (0.3.69)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-openai) (1.97.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-core>=0.3.60->langchain-chroma) (0.4.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-core>=0.3.60->langchain-chroma) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-core>=0.3.60->langchain-chroma) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-core>=0.3.60->langchain-chroma) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/alistermarcdomilies/Library/Python/3.11/lib/python/site-packages (from langchain-core>=0.3.60->langchain-chroma) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/alistermarcdomilies/Library/Python/3.11/lib/python/site-packages (from langchain-core>=0.3.60->langchain-chroma) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-core>=0.3.60->langchain-chroma) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.60->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core>=0.3.60->langchain-chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core>=0.3.60->langchain-chroma) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core>=0.3.60->langchain-chroma) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.4)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (1.4.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (1.35.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (0.21.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (1.73.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (3.11.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromadb) (4.24.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: pyproject_hooks in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.60->langchain-chroma) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.60->langchain-chroma) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (6.31.1)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.35.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.35.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.56b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/alistermarcdomilies/Library/Python/3.11/lib/python/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.33.4)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Downloading langchain_chroma-0.2.4-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: langchain-chroma\n",
      "Successfully installed langchain-chroma-0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 python-dotenv pandas PyMuPDF langchain-chroma langchain-openai langchain langchain-community chromadb rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5b939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "034f7587",
   "metadata": {},
   "source": [
    "## 1. PDF Text Extraction with AWS Textract\n",
    "\n",
    "This Python script defines a class that automates the entire extracting from a PDF document using AWS Textract. It handles the complete cloud workflow by first uploading a local PDF file to an S3 bucket, then initiating an asynchronous analysis job with Textract to detect layout and tables. The script continuously polls AWS to check the job's status and, upon successful completion, retrieves all pages of the analysis results, saving the complete, raw data into a single JSON file on your local machine for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d848ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded to S3: textract-analysis/test_info_extract.pdf\n",
      "Textract Job Started: f3aa1661368d38d9b143054b4213d1cf7d47df39b3b36941ab152ed0ce995513\n",
      "Job status: IN_PROGRESS\n",
      "Job status: SUCCEEDED\n",
      "Retrieved 1 pages of results.\n",
      "Saved raw Textract response to: output/test_info_extract/raw_textract_response.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output/test_info_extract/raw_textract_response.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class TextractJobRunner:\n",
    "    def __init__(self, base_dir=\"output\"):\n",
    "        self.textract = boto3.client(\n",
    "            'textract',\n",
    "            aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "            aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "            region_name=os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "        )\n",
    "        self.s3 = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "            aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "            region_name=os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "        )\n",
    "        self.bucket_name = os.getenv(\"AWS_BUCKET_NAME\")\n",
    "        self.base_dir = base_dir\n",
    "\n",
    "    def run_job_and_save_response(self, file_path):\n",
    "        \"\"\"\n",
    "        Takes a PDF, runs Textract analysis, and saves the raw JSON output.\n",
    "        \"\"\"\n",
    "        file_name_no_ext = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_folder = os.path.join(self.base_dir, file_name_no_ext)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Upload to S3\n",
    "        s3_key = f'textract-analysis/{os.path.basename(file_path)}'\n",
    "        self.s3.upload_file(file_path, self.bucket_name, s3_key)\n",
    "        print(f\"Uploaded to S3: {s3_key}\")\n",
    "\n",
    "        # Start Textract job\n",
    "        response = self.textract.start_document_analysis(\n",
    "            DocumentLocation={'S3Object': {'Bucket': self.bucket_name, 'Name': s3_key}},\n",
    "            FeatureTypes=['LAYOUT', 'TABLES']\n",
    "        )\n",
    "        job_id = response['JobId']\n",
    "        print(f\"Textract Job Started: {job_id}\")\n",
    "\n",
    "        # Poll for completion\n",
    "        while True:\n",
    "            result = self.textract.get_document_analysis(JobId=job_id)\n",
    "            status = result['JobStatus']\n",
    "            print(f\"Job status: {status}\")\n",
    "            if status in ['SUCCEEDED', 'FAILED']:\n",
    "                if status == 'FAILED':\n",
    "                    raise Exception(\"Textract job failed.\")\n",
    "                break\n",
    "            time.sleep(5)\n",
    "\n",
    "        # Retrieve all results using pagination\n",
    "        results = []\n",
    "        next_token = None\n",
    "        while True:\n",
    "            response = self.textract.get_document_analysis(JobId=job_id, NextToken=next_token) if next_token else self.textract.get_document_analysis(JobId=job_id)\n",
    "            results.append(response)\n",
    "            next_token = response.get('NextToken')\n",
    "            if not next_token:\n",
    "                break\n",
    "        print(f\"Retrieved {len(results)} pages of results.\")\n",
    "\n",
    "        # Save the raw results to a JSON file\n",
    "        json_path = os.path.join(output_folder, \"raw_textract_response.json\")\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        print(f\"Saved raw Textract response to: {json_path}\")\n",
    "\n",
    "        return json_path\n",
    "\n",
    "processor = TextractJobRunner()\n",
    "processor.run_job_and_save_response(\"test_info_extract.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd0db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1265db4d",
   "metadata": {},
   "source": [
    "## 2. Textract JSON Parser and Figure Extractor\n",
    "\n",
    "This Python script defines two main functions to process the output from an AWS Textract analysis. The first function, save_layout, parses the raw JSON response to identify and organize all layout elements (like titles and text blocks) into a structured layout.csv file. The second function, save_figures, uses the same JSON data along with the original PDF to locate the coordinates of each figure, extracts the actual images by cropping the PDF, and saves them as individual PNG files into a specified folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ef81ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved raw layout to output/test_info_extract/layout.csv\n",
      "Saved 12 figures to 'output/test_info_extract/figures'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import fitz\n",
    "\n",
    "def save_layout(results, output_folder):\n",
    "    \"\"\"\n",
    "    This function is used to produce a csv from the raw json format.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    layout_counters = defaultdict(int)\n",
    "    reading_order = 0\n",
    "    line_map = {}\n",
    "    \n",
    "    for page in results:\n",
    "        line_map.update({b['Id']: b for b in page['Blocks'] if b['BlockType'] == 'LINE'})\n",
    "        layout_blocks = [b for b in page['Blocks'] if b['BlockType'].startswith('LAYOUT')]\n",
    "\n",
    "        for block in layout_blocks:\n",
    "            layout_key = block['BlockType'].replace('LAYOUT_', '').capitalize()\n",
    "            layout_counters[layout_key] += 1\n",
    "            layout_label = f\"{layout_key} {layout_counters[layout_key]}\"\n",
    "\n",
    "            line_text = ''\n",
    "            for rel in block.get('Relationships', []):\n",
    "                if rel.get('Type') == 'CHILD':\n",
    "                    line_text = ' '.join(line_map.get(i, {}).get('Text', '') for i in rel.get('Ids', []) if i in line_map)\n",
    "\n",
    "            rows.append({\n",
    "                'Page number': block.get('Page', 1),\n",
    "                'Layout': layout_label,\n",
    "                'Text': line_text.strip(),\n",
    "                'Reading Order': reading_order,\n",
    "                'Confidence score % (Layout)': block.get('Confidence', 0)\n",
    "            })\n",
    "            reading_order += 1\n",
    "\n",
    "    layout_path = os.path.join(output_folder, 'layout.csv')\n",
    "    pd.DataFrame(rows).to_csv(layout_path, index=False)\n",
    "    print(f\"Saved raw layout to {layout_path}\")\n",
    "\n",
    "def save_figures(results, pdf_path, output_folder):\n",
    "    \"\"\"\n",
    "    This function is used to retrieve the figures using the coordinates from raw json file and adds it to the layout.csv.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    all_blocks = [block for page in results for block in page.get('Blocks', [])]\n",
    "    figure_blocks = [b for b in all_blocks if b.get('BlockType') == 'LAYOUT_FIGURE']\n",
    "\n",
    "    for i, block in enumerate(figure_blocks, 1):\n",
    "        page_num = block.get('Page')\n",
    "        page = doc.load_page(page_num - 1)\n",
    "        box = block['Geometry']['BoundingBox']\n",
    "        \n",
    "        clip_rect = fitz.Rect(\n",
    "            box['Left'] * page.rect.width, box['Top'] * page.rect.height,\n",
    "            (box['Left'] + box['Width']) * page.rect.width,\n",
    "            (box['Top'] + box['Height']) * page.rect.height\n",
    "        )\n",
    "        \n",
    "        pix = page.get_pixmap(clip=clip_rect, dpi=200)\n",
    "        output_path = os.path.join(output_folder, f\"figure_{i}.png\")\n",
    "        pix.save(output_path)\n",
    "        \n",
    "    doc.close()\n",
    "    print(f\"Saved {len(figure_blocks)} figures to '{output_folder}'.\")\n",
    "\n",
    "\n",
    "base_dir = \"output\"\n",
    "document_folder = \"test_info_extract\"\n",
    "pdf_file_path = \"test_info_extract.pdf\"\n",
    "figure_output_folder = os.path.join(base_dir, document_folder, \"figures\")\n",
    "\n",
    "output_folder_path = os.path.join(base_dir, document_folder)\n",
    "json_file_path = os.path.join(output_folder_path, \"raw_textract_response.json\")\n",
    "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    results_data = json.load(f)\n",
    "\n",
    "save_layout(results_data, output_folder_path)\n",
    "save_figures(results_data, pdf_file_path, figure_output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd01691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bf979f6",
   "metadata": {},
   "source": [
    "## 3. CSV and Markdown Generation from Layout Data \n",
    "\n",
    "This Python script automates the final step of document reconstruction by taking a layout.csv file and a folder of previously extracted figure images as input. It first reads the CSV and systematically finds every row corresponding to a figure, updating its 'Text' column with the correct relative path to the saved image file. After saving this updated data to a new layout_with_figures.csv, the script then generates a complete final_layout.md file, converting titles to Markdown headers and the newly added figure paths into proper image links, effectively creating a readable version of the original document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "513a10c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 12 figure image files.\n",
      "\n",
      "Successfully created new CSV with integrated figure filenames: output/test_info_extract/layout_with_figures.csv\n",
      "Successfully created Markdown file: output/test_info_extract/final_layout.md\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "csv_path = os.path.join(output_folder_path, 'layout.csv')\n",
    "figures_folder_path = os.path.join(output_folder_path, 'figures')\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_path, na_filter=False)\n",
    "\n",
    "figure_files = sorted(\n",
    "    [f for f in os.listdir(figures_folder_path) if f.startswith('figure_') and f.endswith('.png')],\n",
    "    key=lambda x: int(re.search(r'figure_(\\d+)\\.png', x).group(1))\n",
    ")\n",
    "print(f\"\\nFound {len(figure_files)} figure image files.\")\n",
    "\n",
    "figure_rows_indices = df[df['Layout'].str.startswith('Figure', na=False)].index\n",
    "\n",
    "# Loop through the figure rows and update the 'Text' column.\n",
    "for i, df_index in enumerate(figure_rows_indices):\n",
    "    figure_path = os.path.join('figures', figure_files[i])\n",
    "    df.loc[df_index, 'Text'] = figure_path\n",
    "\n",
    "output_csv_path = os.path.join(output_folder_path, 'layout_with_figures.csv')\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"\\nSuccessfully created new CSV with integrated figure filenames: {output_csv_path}\")\n",
    "\n",
    "md_content = []\n",
    "for index, row in df.iterrows():\n",
    "    layout_type = str(row.get('Layout', '')).split(' ')[0]\n",
    "    text = str(row.get('Text', ''))\n",
    "\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    if layout_type == 'Title':\n",
    "        md_content.append(f\"# {text}\\n\")\n",
    "    elif layout_type == 'Header':\n",
    "        md_content.append(f\"## {text}\\n\")\n",
    "    elif layout_type == 'Figure':\n",
    "        md_content.append(f\"![{text}]({text})\\n\")\n",
    "    else: \n",
    "        md_content.append(f\"{text}\\n\")\n",
    "\n",
    "# Save the final markdown content to a file.\n",
    "md_path = os.path.join(output_folder_path, 'final_layout.md')\n",
    "with open(md_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"\\n\".join(md_content))\n",
    "print(f\"Successfully created Markdown file: {md_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2655799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c30feb70",
   "metadata": {},
   "source": [
    "## 4. Contextual Image Summarization\n",
    "\n",
    "This Python script automates the process of generating rich, contextual descriptions for figures listed in a CSV file. It iterates through the layout data, and for each figure, it uploads the corresponding local image file to an AWS S3 bucket, generating a temporary, secure pre-signed URL. This URL, along with the text immediately before and after the figure, is then used to create a dynamic prompt for a large language model (gpt-4o-mini) via LangChain. After processing all figures in a batch, the script collects the AI-generated summaries and updates the original layout data, saving the final, enriched content into a new CSV file named layout_with_summaries.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff546797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: figure_1.png\n",
      "Description: The image is a bar graph comparing energy consumption in kilowatt-hours (kWh) among three categories of homes: \"You,\" \"Similar nearby homes,\" and \"Efficient nearby homes.\" \n",
      "\n",
      "1. The first bar, labeled \"You,\" is colored teal and reaches a height corresponding to 125 kWh, indicating your energy usage. \n",
      "2. The second bar, for \"Similar nearby homes,\" is colored orange and has a height corresponding to 103 kWh, suggesting that these homes consume less energy than yours.\n",
      "3. The third bar, labeled \"Efficient nearby homes,\" is green and reaches a height of 49 kWh, representing the lowest energy usage, highlighting the efficiency of these homes.\n",
      "\n",
      "The data visualization effectively illustrates that your energy consumption is 18% more than that of the similar nearby homes and significantly higher than that of the efficient nearby homes, which may imply that there are opportunities for improving energy efficiency in your own home.\n",
      "\n",
      "File: figure_2.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_3.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_4.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_5.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_6.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_7.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_8.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_9.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_10.png\n",
      "Description: The image is a line graph comparing annual electricity use in kilowatt-hours (kWh) for three categories: \"You\" (represented by a blue line), \"Similar Homes\" (orange line), and \"Efficient Homes\" (green line). \n",
      "\n",
      "- The vertical axis represents electricity usage in kWh, ranging from 0 to 200.\n",
      "- The horizontal axis shows the months from April to March.\n",
      "\n",
      "- The blue line for \"You\" fluctuates, reaching its peak usage in the middle of the graph, indicating higher electricity consumption compared to both of the other categories.\n",
      "- The orange line for \"Similar Homes\" shows a moderate increase before plateauing, suggesting a more consistent electricity usage pattern.\n",
      "- The green line for \"Efficient Homes\" is consistently the lowest, reflecting lower electricity consumption across the same period.\n",
      "\n",
      "This graph illustrates how the user's electricity consumption compares to peers and more efficient homes, providing a visual insight into energy efficiency.\n",
      "\n",
      "File: figure_11.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_12.png\n",
      "Description: icon\n",
      "\n",
      "\n",
      "Successfully created final CSV with summaries: output/test_info_extract/layout_with_summaries.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def upload_image_to_s3(local_path, bucket_name, s3_client):\n",
    "    \"\"\"\n",
    "    Uploads a local image file to an S3 bucket and returns a temporary,\n",
    "    secure pre-signed URL valid for one hour.\n",
    "    \"\"\"\n",
    "    s3_key = f\"figures/{os.path.basename(local_path)}\"\n",
    "    s3_client.upload_file(local_path, bucket_name, s3_key)\n",
    "    # Generate a pre-signed URL that grants temporary access\n",
    "    url = s3_client.generate_presigned_url(\n",
    "        'get_object',\n",
    "        Params={'Bucket': bucket_name, 'Key': s3_key},\n",
    "        ExpiresIn=3600 \n",
    "    )\n",
    "    return url\n",
    "\n",
    "csv_path = os.path.join(output_folder_path, 'layout_with_figures.csv')\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = os.getenv(\"AWS_BUCKET_NAME\")\n",
    "\n",
    "batch_input = []\n",
    "figure_filenames_in_order = []\n",
    "for i, row in df.iterrows():\n",
    "    if str(row.get('Layout')).startswith('Figure'):\n",
    "        image_path = os.path.join(output_folder_path, row['Text'])\n",
    "\n",
    "        # Get context from surrounding text rows\n",
    "        text_before = df.loc[i - 1, 'Text'] if i > 0 else \"No text before.\"\n",
    "        text_after = df.loc[i + 1, 'Text'] if i < len(df) - 1 else \"No text after.\"\n",
    "        \n",
    "        # Build the dynamic prompt for this specific figure\n",
    "        dynamic_prompt = f\"\"\"Describe the image in detail. It is part of a home energy report.\n",
    "\n",
    "        CONTEXT BEFORE IMAGE: \"{text_before}\"\n",
    "        CONTEXT AFTER IMAGE: \"{text_after}\"\n",
    "\n",
    "        **Your Task:**\n",
    "        1.  First, determine if the image is a simple, non-data-carrying icon (e.g., a lightbulb, checkmark, warning sign).\n",
    "        2.  If it IS a simple icon, your entire response must be the single word: `icon`. Do not provide any other text or explanation.\n",
    "        3.  If it is NOT a simple icon, describe the image in detail. Be specific about data visualizations like bar plots, line graphs, or pie charts. Analyze what the data represents using the provided context.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Upload the image to S3 and get the secure URL\n",
    "        image_s3_url = upload_image_to_s3(image_path, bucket_name, s3_client)\n",
    "        \n",
    "        if image_s3_url:\n",
    "            batch_input.append({\n",
    "                \"image_url_input\": image_s3_url,\n",
    "                \"prompt_text\": dynamic_prompt,\n",
    "                \"original_path\": os.path.basename(image_path)\n",
    "            })\n",
    "            figure_filenames_in_order.append(os.path.basename(image_path))\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"user\",\n",
    "        [\n",
    "            {\"type\": \"text\", \"text\": \"{prompt_text}\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": \"{image_url_input}\"},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# Run the Batch Process\n",
    "if batch_input:\n",
    "\n",
    "    image_summaries = chain.batch(batch_input, {\"max_concurrency\": 5})\n",
    "    for i, summary in enumerate(image_summaries):\n",
    "        filename = figure_filenames_in_order[i]\n",
    "        print(f\"File: {filename}\")\n",
    "        print(f\"Description: {summary}\\n\")\n",
    "\n",
    "    figure_indices = df[df['Layout'].str.startswith('Figure', na=False)].index.tolist()\n",
    "\n",
    "    summary_counter = 0\n",
    "    for idx in figure_indices:\n",
    "        if summary_counter < len(image_summaries):\n",
    "            original_layout_label = df.loc[idx, 'Layout']\n",
    "            new_summary = image_summaries[summary_counter]\n",
    "            \n",
    "            df.loc[idx, 'Text'] = new_summary\n",
    "            \n",
    "            summary_counter += 1\n",
    "\n",
    "    output_dir = os.path.dirname(csv_path) or '.'\n",
    "    output_path = os.path.join(output_dir, 'layout_with_summaries.csv')\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nSuccessfully created final CSV with summaries: {output_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"No figures found in the CSV to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca94609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "570fb2a9",
   "metadata": {},
   "source": [
    "## 5. Multimodal Data Preparation for RAG\n",
    "\n",
    "This Python script prepares the data structure for a Retrieval-Augmented Generation (RAG) system by loading two separate CSV files: one containing the original document layout with figure paths, and another with AI-generated summaries. It processes this data by creating \"parent\" documents from the original content to serve as the ground truth for retrieval. It then applies a custom chunking logic to the AI-generated summaries, iteratively grouping them into larger, context-rich \"child\" documents up to a 500-character limit. The final output consists of two aligned sets of documents (original parents and chunked summary children), structured for use in a MultiVectorRetriever where searches can be performed on the rich summaries to retrieve the original, precise content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01563ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and sorted data from both CSV files.\n",
      "Creating parent documents and custom child chunks...\n",
      "Created 7 child chunks from 28 parent documents.\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Content:\n",
      "Title 1: Home Energy Report: electricity\n",
      "Text 1: March report Account number: 954137 Service address: 1627 Tulip Lane\n",
      "Text 2: Dear JILL DOE, here is your usage analysis for March.\n",
      "Text 3: Your electric use:\n",
      "Text 4: Above typical use\n",
      "Text 5: 18% more than similar nearby homes\n",
      "--------------------\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Content:\n",
      "Figure 1: The image is a bar graph comparing energy consumption in kilowatt-hours (kWh) among three categories of homes: \"You,\" \"Similar nearby homes,\" and \"Efficient nearby homes.\" \n",
      "\n",
      "1. The first bar, labeled \"You,\" is colored teal and reaches a height corresponding to 125 kWh, indicating your energy usage. \n",
      "2. The second bar, for \"Similar nearby homes,\" is colored orange and has a height corresponding to 103 kWh, suggesting that these homes consume less energy than yours.\n",
      "3. The third bar, labeled \"Efficient nearby homes,\" is green and reaches a height of 49 kWh, representing the lowest energy usage, highlighting the efficiency of these homes.\n",
      "\n",
      "The data visualization effectively illustrates that your energy consumption is 18% more than that of the similar nearby homes and significantly higher than that of the efficient nearby homes, which may imply that there are opportunities for improving energy efficiency in your own home.\n",
      "--------------------\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Content:\n",
      "Text 6: Nearby homes are defined as\n",
      "Text 7: Other homes with electricity\n",
      "Text 8: Homes within 9 km\n",
      "Text 9: Homes within +/- 300 sq. ft.\n",
      "Text 10: Nearby homes are based on fuel, distance and size. Square footage is collected from public information sources. Efficient nearby homes are the top 15 per cent efficient of similar-sized homes nearby.\n",
      "Text 11: Monthly savings tip: Do full laundry loads.\n",
      "Text 12: Waiting until you have a full load to run your laundry can save up to 6% of your energy use.\n",
      "--------------------\n",
      "\n",
      "--- Chunk 4 ---\n",
      "Content:\n",
      "Text 13: Watch this space for new ways to save energy each month.\n",
      "Footer 1: Turn over for more savings ideas.\n",
      "Title 2: Your top three tailored energy-saving tips\n",
      "Text 14: Caulk windows and doors Save money and energy\n",
      "Text 15: One of the biggest money-wasters in your home is drafty windows and doors. Caulking drafty areas is a simple DIY project that will pay off.\n",
      "Text 16: Upgrade your refrigerator Look for an Energy Star label\n",
      "--------------------\n",
      "\n",
      "--- Chunk 5 ---\n",
      "Content:\n",
      "Text 17: Older model refrigerators are very inefficient. You can make up the cost of a new Energy Star refrigerator in energy savings in just a few years.\n",
      "Text 18: Adjust thermostat settings Biggest energy saving option\n",
      "Text 19: Set your smart thermostat to save more 78�� energy during high-cost hours. Pre-heat your home on cold days so that you can save more energy.\n",
      "--------------------\n",
      "\n",
      "--- Chunk 6 ---\n",
      "Content:\n",
      "Figure 10: The image is a line graph comparing annual electricity use in kilowatt-hours (kWh) for three categories: \"You\" (represented by a blue line), \"Similar Homes\" (orange line), and \"Efficient Homes\" (green line). \n",
      "\n",
      "- The vertical axis represents electricity usage in kWh, ranging from 0 to 200.\n",
      "- The horizontal axis shows the months from April to March.\n",
      "\n",
      "- The blue line for \"You\" fluctuates, reaching its peak usage in the middle of the graph, indicating higher electricity consumption compared to both of the other categories.\n",
      "- The orange line for \"Similar Homes\" shows a moderate increase before plateauing, suggesting a more consistent electricity usage pattern.\n",
      "- The green line for \"Efficient Homes\" is consistently the lowest, reflecting lower electricity consumption across the same period.\n",
      "\n",
      "This graph illustrates how the user's electricity consumption compares to peers and more efficient homes, providing a visual insight into energy efficiency.\n",
      "--------------------\n",
      "\n",
      "--- Chunk 7 ---\n",
      "Content:\n",
      "Text 20: Save more this spring\n",
      "Text 21: Reduce use and save money on your electric bill with these thorough tips, from the kitchen to the laundry room.\n",
      "Text 22: Evaluate your energy efficiency\n",
      "Text 23: Bring in the professionals! Assess your home's energy efficiency with a Home Energy Audit.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "csv_figures_path = 'output/test_info_extract/layout_with_figures.csv'\n",
    "csv_summaries_path = 'output/test_info_extract/layout_with_summaries.csv'\n",
    "\n",
    "try:\n",
    "    df_figures = pd.read_csv(csv_figures_path, na_filter=False)\n",
    "    df_summaries = pd.read_csv(csv_summaries_path, na_filter=False)\n",
    "    df_figures_sorted = df_figures.sort_values(by='Reading Order').reset_index(drop=True)\n",
    "    df_summaries_sorted = df_summaries.sort_values(by='Reading Order').reset_index(drop=True)\n",
    "    condition = (df_summaries_sorted['Layout'].str.lower().str.startswith('figure', na=False)) & \\\n",
    "                (df_summaries_sorted['Text'].str.lower() == 'icon')\n",
    "    orders_to_remove = df_summaries_sorted[condition]['Reading Order']\n",
    "    df_figures_sorted = df_figures_sorted[~df_figures_sorted['Reading Order'].isin(orders_to_remove)].reset_index(drop=True)\n",
    "    df_summaries_sorted = df_summaries_sorted[~df_summaries_sorted['Reading Order'].isin(orders_to_remove)].reset_index(drop=True)\n",
    "    assert len(df_figures_sorted) == len(df_summaries_sorted), \"CSV files must have the same number of rows.\"\n",
    "    print(f\"Successfully loaded and sorted data from both CSV files.\")\n",
    "except (FileNotFoundError, KeyError, AssertionError) as e:\n",
    "    print(f\"Error loading or processing CSV files: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Create Parent Documents and Custom Child Chunks\n",
    "print(\"Creating parent documents and custom child chunks...\")\n",
    "parent_documents = []\n",
    "child_docs = []\n",
    "parent_doc_ids = []\n",
    "\n",
    "for index, row in df_figures_sorted.iterrows():\n",
    "    doc_id = str(uuid.uuid4())\n",
    "    parent_doc_ids.append(doc_id)\n",
    "    parent_content = f\"{row['Layout']}: {row['Text']}\"\n",
    "    parent_documents.append(Document(page_content=parent_content, metadata={\"doc_id\": doc_id}))\n",
    "\n",
    "max_chars = 500\n",
    "current_chunk_text = \"\"\n",
    "ids_for_current_chunk = []\n",
    "texts_to_chunk = [f\"{row['Layout']}: {row['Text']}\" for index, row in df_summaries_sorted.iterrows()]\n",
    "\n",
    "for i, text_to_add in enumerate(texts_to_chunk):\n",
    "    doc_id = parent_doc_ids[i]\n",
    "    if not current_chunk_text:\n",
    "        current_chunk_text = text_to_add\n",
    "        ids_for_current_chunk.append(doc_id)\n",
    "        continue\n",
    "    if len(current_chunk_text) + len(text_to_add) + 1 > max_chars:\n",
    "        metadata = {\"parent_doc_ids\": \",\".join(ids_for_current_chunk)}\n",
    "        child_docs.append(Document(page_content=current_chunk_text, metadata=metadata))\n",
    "        current_chunk_text = text_to_add\n",
    "        ids_for_current_chunk = [doc_id]\n",
    "    else:\n",
    "        current_chunk_text += \"\\n\" + text_to_add\n",
    "        ids_for_current_chunk.append(doc_id)\n",
    "if current_chunk_text:\n",
    "    metadata = {\"parent_doc_ids\": \",\".join(ids_for_current_chunk)}\n",
    "    child_docs.append(Document(page_content=current_chunk_text, metadata=metadata))\n",
    "print(f\"Created {len(child_docs)} child chunks from {len(parent_documents)} parent documents.\")\n",
    "\n",
    "for i, chunk in enumerate(child_docs):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(\"Content:\")\n",
    "    print(chunk.page_content)\n",
    "    print(\"--------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c97aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86a6c349",
   "metadata": {},
   "source": [
    "## 6. Hybrid Search and Parent Document Retrieval\n",
    "\n",
    "This Python script sets up a sophisticated, two-part retrieval system for a RAG pipeline. First, it creates a hybrid search mechanism by combining a keyword-based retriever (BM25Retriever) with a semantic vector-based retriever (Chroma), allowing it to find documents based on both exact words and contextual meaning. This hybrid search is performed on a collection of  child documents (which includes AI-generated summariesfor figures). The script then defines a custom function that takes the results of this hybrid search, extracts the IDs of the original \"parent\" documents they correspond to, and fetches those complete parent documents from an in-memory store, ensuring that the final context to be fed to the generation langeuage model is the full, original source content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e82d908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully built the vector store and retriever.\n"
     ]
    }
   ],
   "source": [
    "# Set up the Retriever\n",
    "emb = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(collection_name=\"rag_s3_ordered_retriever\", embedding_function=emb)\n",
    "vectorstore.add_documents(child_docs)\n",
    "store = InMemoryStore()\n",
    "store.mset(list(zip(parent_doc_ids, parent_documents)))\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(child_docs)\n",
    "bm25_retriever.k = 5\n",
    "semantic_retriever = vectorstore.as_retriever(search_kwargs={'k': 5})\n",
    "hybrid_retriever = EnsembleRetriever(retrievers=[bm25_retriever, semantic_retriever], weights=[0.5, 0.5])\n",
    "\n",
    "def get_parents_from_hybrid_search(query):\n",
    "    child_chunks = hybrid_retriever.invoke(query)\n",
    "    \n",
    "    # Get the string of parent IDs from the metadata\n",
    "    ordered_parent_ids = []\n",
    "    seen_ids = set()\n",
    "    for chunk in child_chunks:\n",
    "        parent_ids_str = chunk.metadata.get(\"parent_doc_ids\", \"\")\n",
    "        for p_id in parent_ids_str.split(\",\"):\n",
    "            if p_id and p_id not in seen_ids:\n",
    "                ordered_parent_ids.append(p_id)\n",
    "                seen_ids.add(p_id)\n",
    "                \n",
    "    return store.mget(ordered_parent_ids)\n",
    "\n",
    "retriever = RunnableLambda(get_parents_from_hybrid_search)\n",
    "print(\"\\nSuccessfully built the vector store and retriever.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ace23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "828619be",
   "metadata": {},
   "source": [
    "## 7. Dynamic Multimodal RAG Chain\n",
    "\n",
    "This Python script defines the final, dynamic stage of a Retrieval-Augmented Generation (RAG) pipeline designed to handle both text and images. It creates a chain that first retrieves relevant documents from your vector store. A custom parsing function then processes these documents: if a document represents a figure, it uploads the corresponding image to AWS S3 on-the-fly to generate a secure, temporary URL. Finally, another function dynamically assembles a multimodal prompt for the language model, combining all the retrieved text with any generated image URLs, allowing the AI to generate a comprehensive answer based on both the textual and visual context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45530fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docs_and_generate_urls(docs):\n",
    "    image_urls, text_content = [], []\n",
    "    for doc in docs:\n",
    "        if not doc: \n",
    "            continue\n",
    "        \n",
    "        page_content = doc.page_content\n",
    "        # Check if the document is a figure\n",
    "        if \"Figure\" in page_content.split(':')[0]:\n",
    "            relative_fig_path = page_content.split(': ', 1)[1]\n",
    "            local_fig_path = os.path.join(output_folder_path, relative_fig_path)\n",
    "            \n",
    "            url = upload_image_to_s3(local_fig_path, bucket_name, s3_client)\n",
    "            if url:\n",
    "                image_urls.append(url)\n",
    "                # Add the figure's layout label as text context\n",
    "                text_content.append(page_content.split(':')[0] + \":\")\n",
    "        else:\n",
    "            text_content.append(page_content)\n",
    "            \n",
    "    return {\"images\": image_urls, \"texts\": text_content}\n",
    "\n",
    "def build_prompt_with_urls(inputs):\n",
    "    context_text = \"\\n\".join(inputs[\"context\"]['texts']).strip()\n",
    "    prompt_content = [{\n",
    "        \"type\": \"text\",\n",
    "        \"text\": f\"\"\"Answer the question based only on the following context.\n",
    "\n",
    "        Context:\n",
    "        ---\n",
    "        {context_text}\n",
    "        ---\n",
    "\n",
    "        Question: {inputs['question']}\n",
    "        \"\"\"\n",
    "            }]\n",
    "    for url in inputs[\"context\"][\"images\"]:\n",
    "        prompt_content.append({\"type\": \"image_url\", \"image_url\": {\"url\": url}})\n",
    "    return [HumanMessage(content=prompt_content)]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "chain = (\n",
    "    {\"context\": retriever | RunnableLambda(parse_docs_and_generate_urls), \"question\": RunnablePassthrough()}\n",
    "    | RunnableLambda(build_prompt_with_urls)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e521d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f09d40e",
   "metadata": {},
   "source": [
    "## 8. RAG Pipeline Execution with Source Inspection\n",
    "\n",
    "This Python script demonstrates how to run and inspect the results of the complete Retrieval-Augmented Generation (RAG) pipeline. It defines a sample query and then invokes a special chain designed for debugging, which returns not only the final, AI-generated answer but also the specific \"reference chunks\" (the parent documents) that were retrieved from the vector store to create that answer. The script then prints both the retrieved source documents for verification and the final answer, providing a clear way to understand what information the language model used as its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f5a0f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example Search for: 'What was the energy usage compared to neighbors?' ---\n",
      "\n",
      "Generating answer...\n",
      "Retrieving reference documents...\n",
      "\n",
      "--- REFERENCE CHUNKS (Parent Documents) ---\n",
      "Figure 10: figures/figure_10.png\n",
      "Figure 1: figures/figure_1.png\n",
      "Text 20: Save more this spring\n",
      "Text 21: Reduce use and save money on your electric bill with these thorough tips, from the kitchen to the laundry room.\n",
      "Text 22: Evaluate your energy efficiency\n",
      "Text 23: Bring in the professionals! Assess your home's energy efficiency with a Home Energy Audit.\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "Your annual electricity use is 125 kWh, which is higher than similar nearby homes at 103 kWh and significantly higher than efficient nearby homes at 49 kWh.\n"
     ]
    }
   ],
   "source": [
    "query = \"What was the energy usage compared to neighbors?\"\n",
    "\n",
    "print(f\"\\n--- Example Search for: '{query}' ---\")\n",
    "\n",
    "print(\"\\nGenerating answer...\")\n",
    "answer = chain.invoke(query)\n",
    "\n",
    "print(\"Retrieving reference documents...\")\n",
    "reference_docs = retriever.invoke(query)\n",
    "\n",
    "print(\"\\n--- REFERENCE CHUNKS (Parent Documents) ---\")\n",
    "if reference_docs:\n",
    "    for doc in reference_docs:\n",
    "        if doc:\n",
    "            print(doc.page_content)\n",
    "else:\n",
    "    print(\"No context retrieved.\")\n",
    "\n",
    "print(\"\\n--- FINAL ANSWER ---\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21a9317a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example Search for: 'Give me tips on how to save energy and reduce utility cost in my home.' ---\n",
      "\n",
      "Generating answer...\n",
      "Retrieving reference documents...\n",
      "\n",
      "--- REFERENCE CHUNKS (Parent Documents) ---\n",
      "Text 20: Save more this spring\n",
      "Text 21: Reduce use and save money on your electric bill with these thorough tips, from the kitchen to the laundry room.\n",
      "Text 22: Evaluate your energy efficiency\n",
      "Text 23: Bring in the professionals! Assess your home's energy efficiency with a Home Energy Audit.\n",
      "Text 13: Watch this space for new ways to save energy each month.\n",
      "Footer 1: Turn over for more savings ideas.\n",
      "Title 2: Your top three tailored energy-saving tips\n",
      "Text 14: Caulk windows and doors Save money and energy\n",
      "Text 15: One of the biggest money-wasters in your home is drafty windows and doors. Caulking drafty areas is a simple DIY project that will pay off.\n",
      "Text 16: Upgrade your refrigerator Look for an Energy Star label\n",
      "Text 17: Older model refrigerators are very inefficient. You can make up the cost of a new Energy Star refrigerator in energy savings in just a few years.\n",
      "Text 18: Adjust thermostat settings Biggest energy saving option\n",
      "Text 19: Set your smart thermostat to save more 78�� energy during high-cost hours. Pre-heat your home on cold days so that you can save more energy.\n",
      "Figure 1: figures/figure_1.png\n",
      "Figure 10: figures/figure_10.png\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "Here are some tips to save energy and reduce utility costs in your home:\n",
      "\n",
      "1. **Caulk Windows and Doors**: Seal drafty areas to prevent heat loss, which is a simple DIY project that can lead to significant savings.\n",
      "\n",
      "2. **Upgrade Your Refrigerator**: Consider replacing older models with Energy Star-rated refrigerators, which are more efficient and can save you money on energy bills over time.\n",
      "\n",
      "3. **Adjust Thermostat Settings**: Set your smart thermostat to 78°F during high-cost hours and pre-heat your home on cold days to maximize energy savings.\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me tips on how to save energy and reduce utility cost in my home.\"\n",
    "\n",
    "print(f\"\\n--- Example Search for: '{query}' ---\")\n",
    "\n",
    "print(\"\\nGenerating answer...\")\n",
    "answer = chain.invoke(query)\n",
    "\n",
    "print(\"Retrieving reference documents...\")\n",
    "reference_docs = retriever.invoke(query)\n",
    "\n",
    "print(\"\\n--- REFERENCE CHUNKS (Parent Documents) ---\")\n",
    "if reference_docs:\n",
    "    for doc in reference_docs:\n",
    "        if doc:\n",
    "            print(doc.page_content)\n",
    "else:\n",
    "    print(\"No context retrieved.\")\n",
    "\n",
    "print(\"\\n--- FINAL ANSWER ---\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ab7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
