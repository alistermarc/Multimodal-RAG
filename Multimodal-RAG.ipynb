{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db5b50be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (1.39.6)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: botocore<1.40.0,>=1.39.6 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from boto3) (1.39.6)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from boto3) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from botocore<1.40.0,>=1.39.6->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from botocore<1.40.0,>=1.39.6->boto3) (1.26.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.40.0,>=1.39.6->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd7bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class TextractProcessor:\n",
    "    def __init__(self, base_dir, bucket_name=None):\n",
    "        self.textract = boto3.client(\n",
    "            'textract',\n",
    "            aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "            aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "            region_name=os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "        )\n",
    "        self.s3 = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "            aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "            region_name=os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "        )\n",
    "        self.bucket_name = bucket_name or os.getenv(\"AWS_BUCKET_NAME\")\n",
    "        self.base_dir = base_dir\n",
    "\n",
    "    def process_pdf(self, file_path, save_to_disk=True):\n",
    "        file_name_no_ext = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_folder = os.path.join(self.base_dir, file_name_no_ext)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Upload to S3\n",
    "        s3_key = f'{os.path.basename(self.base_dir)}/{os.path.basename(file_path)}'\n",
    "        self.s3.upload_file(file_path, self.bucket_name, s3_key)\n",
    "        print(f\"Uploaded to S3: {s3_key}\")\n",
    "\n",
    "        # Start Textract job\n",
    "        response = self.textract.start_document_analysis(\n",
    "            DocumentLocation={'S3Object': {'Bucket': self.bucket_name, 'Name': s3_key}},\n",
    "            FeatureTypes=['LAYOUT', 'TABLES']\n",
    "        )\n",
    "        job_id = response['JobId']\n",
    "        print(f\"Textract Job Started: {job_id}\")\n",
    "\n",
    "        # Poll for completion\n",
    "        while True:\n",
    "            result = self.textract.get_document_analysis(JobId=job_id)\n",
    "            status = result['JobStatus']\n",
    "            print(f\"Job status: {status}\")\n",
    "            if status in ['SUCCEEDED', 'FAILED']:\n",
    "                if status == 'FAILED':\n",
    "                    raise Exception(\"Textract job failed.\")\n",
    "                break\n",
    "            time.sleep(5)\n",
    "\n",
    "        # Retrieve all results\n",
    "        results = []\n",
    "        next_token = None\n",
    "        while True:\n",
    "            response = self.textract.get_document_analysis(JobId=job_id, NextToken=next_token) if next_token else self.textract.get_document_analysis(JobId=job_id)\n",
    "            results.append(response)\n",
    "            next_token = response.get('NextToken')\n",
    "            if not next_token:\n",
    "                break\n",
    "\n",
    "        # Extract layout and tables\n",
    "        layout_df = self.extract_layout(results)\n",
    "        tables = self.extract_tables(results)\n",
    "\n",
    "        # Optionally save\n",
    "        if save_to_disk:\n",
    "            layout_df.to_csv(os.path.join(output_folder, \"layout.csv\"), index=False)\n",
    "            for i, table in enumerate(tables, 1):\n",
    "                with open(os.path.join(output_folder, f\"table-{i}.csv\"), \"w\") as f:\n",
    "                    f.write(table)\n",
    "\n",
    "        return layout_df, tables\n",
    "\n",
    "    def generate_layout_figures(self, results, output_folder):\n",
    "        \"\"\"Save PNG images per page with layout bounding boxes.\"\"\"\n",
    "        page_images = []\n",
    "        for page_num, page in enumerate(results, start=1):\n",
    "            blocks = page['Blocks']\n",
    "            layout_blocks = [b for b in blocks if b['BlockType'].startswith('LAYOUT')]\n",
    "            image_block = next((b for b in blocks if b['BlockType'] == 'PAGE'), None)\n",
    "            width, height = 1000, 1300  # fixed size for visualization\n",
    "\n",
    "            # Create blank white image\n",
    "            img = Image.new('RGB', (width, height), color='white')\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(img)\n",
    "\n",
    "            for block in layout_blocks:\n",
    "                box = block['Geometry']['BoundingBox']\n",
    "                left = box['Left'] * width\n",
    "                top = box['Top'] * height\n",
    "                box_width = box['Width'] * width\n",
    "                box_height = box['Height'] * height\n",
    "\n",
    "                rect = plt.Rectangle((left, top), box_width, box_height,\n",
    "                                    linewidth=2, edgecolor='blue', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                ax.text(left, top - 10, block['BlockType'].replace('LAYOUT_', ''), color='blue', fontsize=8)\n",
    "\n",
    "            ax.axis('off')\n",
    "            fig.tight_layout(pad=0)\n",
    "            fig.canvas.draw()\n",
    "\n",
    "            # Save image\n",
    "            img_path = os.path.join(output_folder, f\"layout_page_{page_num}.png\")\n",
    "            fig.savefig(img_path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close(fig)\n",
    "\n",
    "            page_images.append(img_path)\n",
    "\n",
    "        return page_images\n",
    "\n",
    "    def extract_layout(self, results):\n",
    "        rows = []\n",
    "        layout_counters = defaultdict(int)\n",
    "        reading_order = 0\n",
    "        line_map = {}\n",
    "        output_folder = os.path.join(self.base_dir, \"figures\")\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        page_figures = self.generate_layout_figures(results, output_folder)\n",
    "\n",
    "        for page_num, page in enumerate(results, start=1):\n",
    "            line_map.update({b['Id']: b for b in page['Blocks'] if b['BlockType'] == 'LINE'})\n",
    "            layout_blocks = [b for b in page['Blocks'] if b['BlockType'].startswith('LAYOUT')]\n",
    "\n",
    "            for block in layout_blocks:\n",
    "                layout_key = block['BlockType'].replace('LAYOUT_', '').capitalize()\n",
    "                layout_counters[layout_key] += 1\n",
    "                layout_label = f\"{layout_key} {layout_counters[layout_key]}\"\n",
    "\n",
    "                line_text = ''\n",
    "                for rel in block.get('Relationships', []):\n",
    "                    if rel.get('Type') == 'CHILD':\n",
    "                        line_text = ' '.join(line_map.get(i, {}).get('Text', '') for i in rel.get('Ids', []) if i in line_map)\n",
    "\n",
    "                rows.append({\n",
    "                    'Page number': block.get('Page', 1),\n",
    "                    'Layout': layout_label,\n",
    "                    'Text': line_text.strip(),\n",
    "                    'Reading Order': reading_order,\n",
    "                    'Confidence score % (Layout)': block['Confidence'],\n",
    "                    'Figure': page_figures[page_num - 1]\n",
    "                })\n",
    "                reading_order += 1\n",
    "\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "    def extract_tables(self, results):\n",
    "        table_index = 1\n",
    "        tables_output = []\n",
    "        for page in results:\n",
    "            blocks = page['Blocks']\n",
    "            blocks_map = {b['Id']: b for b in blocks}\n",
    "            table_blocks = [b for b in blocks if b['BlockType'] == 'TABLE']\n",
    "            for table in table_blocks:\n",
    "                rows, scores = self.get_table_rows(table, blocks_map)\n",
    "                table_id = f\"Table_{table_index}\"\n",
    "                table_csv = f\"Table: {table_id}\\n\\n\"\n",
    "\n",
    "                col_count = 0\n",
    "                for row in sorted(rows):\n",
    "                    cols = rows[row]\n",
    "                    col_count = len(cols)\n",
    "                    table_csv += ','.join(cols[col] for col in sorted(cols)) + '\\n'\n",
    "\n",
    "                table_csv += '\\n\\n Confidence Scores % (Table Cell) \\n'\n",
    "                for i, score in enumerate(scores, 1):\n",
    "                    table_csv += score + (',' if i % col_count else '\\n')\n",
    "\n",
    "                tables_output.append(table_csv)\n",
    "                table_index += 1\n",
    "        return tables_output\n",
    "\n",
    "    def get_text(self, cell, blocks_map):\n",
    "        text = ''\n",
    "        for rel in cell.get('Relationships', []):\n",
    "            if rel['Type'] == 'CHILD':\n",
    "                for cid in rel['Ids']:\n",
    "                    word = blocks_map.get(cid, {})\n",
    "                    if word['BlockType'] == 'WORD':\n",
    "                        t = word['Text']\n",
    "                        text += f'\"{t}\" ' if \",\" in t and t.replace(\",\", \"\").isnumeric() else f\"{t} \"\n",
    "                    elif word['BlockType'] == 'SELECTION_ELEMENT' and word.get('SelectionStatus') == 'SELECTED':\n",
    "                        text += 'X '\n",
    "        return text.strip()\n",
    "\n",
    "    def get_table_rows(self, table, blocks_map):\n",
    "        rows, scores = {}, []\n",
    "        for rel in table.get('Relationships', []):\n",
    "            if rel['Type'] == 'CHILD':\n",
    "                for cid in rel['Ids']:\n",
    "                    cell = blocks_map.get(cid)\n",
    "                    if cell and cell['BlockType'] == 'CELL':\n",
    "                        row, col = cell['RowIndex'], cell['ColumnIndex']\n",
    "                        rows.setdefault(row, {})[col] = self.get_text(cell, blocks_map)\n",
    "                        scores.append(str(cell['Confidence']))\n",
    "        return rows, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2c050bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded to S3: output/test_info_extract.pdf\n",
      "Textract Job Started: 91a8ff8f1353db66563e2c64779ae51d70890b480495ee2f425397ba5a490b7d\n",
      "Job status: IN_PROGRESS\n",
      "Job status: SUCCEEDED\n",
      "\n",
      "Extracting figure images from PDF...\n",
      "Extracted and saved 12 figures.\n",
      "\n",
      "Saved final layout CSV to: output\\test_info_extract\\layout.csv\n",
      "\n",
      "--- Final Extracted Layout ---\n",
      "    Page number     Layout                                                                                                                                                                                                     Text  Reading Order  Confidence score % (Layout)\n",
      "0             1    Title 1                                                                                                                                                                          Home Energy Report: electricity              0                    30.859375\n",
      "1             1     Text 1                                                                                                                                     March report Account number: 954137 Service address: 1627 Tulip Lane              1                    26.977539\n",
      "2             1     Text 2                                                                                                                                                    Dear JILL DOE, here is your usage analysis for March.              2                    84.863281\n",
      "3             1     Text 3                                                                                                                                                                                       Your electric use:              3                    88.769531\n",
      "4             1     Text 4                                                                                                                                                                       18% more than similar nearby homes              4                    86.328125\n",
      "5             1   Figure 1                                                                                                                                                                                             figure_1.png              5                    89.599609\n",
      "6             1     Text 5                                                                                                                                                                                        Above typical use              6                    79.882812\n",
      "7             1     Text 6                                                                                                                                                              Monthly savings tip: Do full laundry loads.              7                    94.335938\n",
      "8             1     Text 7                                                                                                                                                                              Nearby homes are defined as              8                    82.373047\n",
      "9             1   Figure 2                                                                                                                                                                                             figure_2.png              9                    66.259766\n",
      "10            1     Text 8                                                                                                                                                                             Other homes with electricity             10                    94.580078\n",
      "11            1   Figure 3                                                                                                                                                                                             figure_3.png             11                    91.162109\n",
      "12            1     Text 9                                                                                                             Waiting until you have a full load to run your laundry can save up to 6% of your energy use.             12                    95.751953\n",
      "13            1   Figure 4                                                                                                                                                                                             figure_4.png             13                    94.238281\n",
      "14            1    Text 10                                                                                                                                                                                        Homes within 9 km             14                    91.943359\n",
      "15            1   Figure 5                                                                                                                                                                                             figure_5.png             15                    96.386719\n",
      "16            1    Text 11                                                                                                                                                                             Homes within +/- 300 sq. ft.             16                    95.117188\n",
      "17            1    Text 12                                                                                                                                                 Watch this space for new ways to save energy each month.             17                    92.480469\n",
      "18            1    Text 13  Nearby homes are based on fuel, distance and size. Square footage is collected from public information sources. Efficient nearby homes are the top 15 per cent efficient of similar-sized homes nearby.             18                    95.361328\n",
      "19            1   Figure 6                                                                                                                                                                                             figure_6.png             19                    65.771484\n",
      "20            1   Footer 1                                                                                                                                                                        Turn over for more savings ideas.             20                    72.265625\n",
      "21            2    Title 2                                                                                                                                                               Your top three tailored energy-saving tips             21                    69.775391\n",
      "22            2    Text 14                                                                                                                                                  Adjust thermostat settings Biggest energy saving option             22                    94.775391\n",
      "23            2    Text 15                                                                                                                                                  Upgrade your refrigerator Look for an Energy Star label             23                    78.125000\n",
      "24            2    Text 16                                                                                                                                                            Caulk windows and doors Save money and energy             24                    80.761719\n",
      "25            2   Figure 7                                                                                                                                                                                             figure_7.png             25                    95.654297\n",
      "26            2    Text 17                                                        Older model refrigerators are very inefficient. You can make up the cost of a new Energy Star refrigerator in energy savings in just a few years.             26                    95.703125\n",
      "27            2    Text 18                                                              One of the biggest money-wasters in your home is drafty windows and doors. Caulking drafty areas is a simple DIY project that will pay off.             27                    87.207031\n",
      "28            2    Text 19                                                             Set your smart thermostat to save more 78�� energy during high-cost hours. Pre-heat your home on cold days so that you can save more energy.             28                    74.609375\n",
      "29            2   Figure 8                                                                                                                                                                                             figure_8.png             29                    96.777344\n",
      "30            2   Figure 9                                                                                                                                                                                             figure_9.png             30                    96.582031\n",
      "31            2  Figure 10                                                                                                                                                                                            figure_10.png             31                    90.966797\n",
      "32            2    Text 20                                                                                                                                                                                    Save more this spring             32                    70.556641\n",
      "33            2    Text 21                                                                                                                                                                          Evaluate your energy efficiency             33                    51.367188\n",
      "34            2  Figure 11                                                                                                                                                                                            figure_11.png             34                    95.019531\n",
      "35            2    Text 22                                                                                                               Bring in the professionals! Assess your home's energy efficiency with a Home Energy Audit.             35                    77.880859\n",
      "36            2  Figure 12                                                                                                                                                                                            figure_12.png             36                    95.605469\n",
      "37            2    Text 23                                                                                          Reduce use and save money on your electric bill with these thorough tips, from the kitchen to the laundry room.             37                    88.134766\n"
     ]
    }
   ],
   "source": [
    "processor = TextractProcessor(base_dir=\"output\")\n",
    "layout_df = processor.process_pdf(\"test_info_extract.pdf\")\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(\"\\n--- Final Extracted Layout ---\")\n",
    "print(layout_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b09e0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded to S3: textract-analysis/test_info_extract.pdf\n",
      "Textract Job Started: 26042474975f6211068256a399faa8d7a88b57c2d1df8046d5c5019e6203eb96\n",
      "Job status: IN_PROGRESS\n",
      "Job status: SUCCEEDED\n",
      "Retrieved 1 pages of results.\n",
      "\n",
      "Saving raw Textract response to: output\\test_info_extract\\raw_textract_response.json\n",
      "Raw JSON response saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class TextractJobRunner:\n",
    "    def __init__(self, base_dir, bucket_name=None):\n",
    "        self.textract = boto3.client(\n",
    "            'textract',\n",
    "            aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "            aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "            region_name=os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "        )\n",
    "        self.s3 = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "            aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "            region_name=os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "        )\n",
    "        self.bucket_name = bucket_name or os.getenv(\"AWS_BUCKET_NAME\")\n",
    "        self.base_dir = base_dir\n",
    "\n",
    "    def run_job_and_save_response(self, file_path):\n",
    "        \"\"\"\n",
    "        Takes a PDF, runs Textract analysis, and saves the raw JSON output.\n",
    "        \"\"\"\n",
    "        file_name_no_ext = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_folder = os.path.join(self.base_dir, file_name_no_ext)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Upload to S3\n",
    "        s3_key = f'textract-analysis/{os.path.basename(file_path)}'\n",
    "        self.s3.upload_file(file_path, self.bucket_name, s3_key)\n",
    "        print(f\"Uploaded to S3: {s3_key}\")\n",
    "\n",
    "        # Start Textract job\n",
    "        # Note: We are still asking for LAYOUT and TABLES to get the most detailed JSON\n",
    "        response = self.textract.start_document_analysis(\n",
    "            DocumentLocation={'S3Object': {'Bucket': self.bucket_name, 'Name': s3_key}},\n",
    "            FeatureTypes=['LAYOUT', 'TABLES']\n",
    "        )\n",
    "        job_id = response['JobId']\n",
    "        print(f\"Textract Job Started: {job_id}\")\n",
    "\n",
    "        # Poll for completion\n",
    "        while True:\n",
    "            result = self.textract.get_document_analysis(JobId=job_id)\n",
    "            status = result['JobStatus']\n",
    "            print(f\"Job status: {status}\")\n",
    "            if status in ['SUCCEEDED', 'FAILED']:\n",
    "                if status == 'FAILED':\n",
    "                    raise Exception(\"Textract job failed.\")\n",
    "                break\n",
    "            time.sleep(5)\n",
    "\n",
    "        # Retrieve all results using pagination\n",
    "        results = []\n",
    "        next_token = None\n",
    "        while True:\n",
    "            response = self.textract.get_document_analysis(JobId=job_id, NextToken=next_token) if next_token else self.textract.get_document_analysis(JobId=job_id)\n",
    "            results.append(response)\n",
    "            next_token = response.get('NextToken')\n",
    "            if not next_token:\n",
    "                break\n",
    "        \n",
    "        print(f\"Retrieved {len(results)} pages of results.\")\n",
    "\n",
    "        # Save the raw results to a JSON file\n",
    "        json_path = os.path.join(output_folder, \"raw_textract_response.json\")\n",
    "        print(f\"\\nSaving raw Textract response to: {json_path}\")\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "            \n",
    "        print(\"Raw JSON response saved successfully.\")\n",
    "        return json_path\n",
    "\n",
    "# --- How to run this script ---\n",
    "if __name__ == '__main__':\n",
    "    # Initialize the class with your base output directory\n",
    "    processor = TextractJobRunner(base_dir=\"output\")\n",
    "    \n",
    "    # Run the process for your PDF\n",
    "    processor.run_job_and_save_response(\"test_info_extract.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e963efb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved layout to output\\test_info_extract\\layout.csv\n",
      "\n",
      "Extracting and saving figures...\n",
      "Saved 12 figures to 'output\\test_info_extract\\figures'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import fitz\n",
    "\n",
    "def save_layout(results, output_folder):\n",
    "    \"\"\"\n",
    "    This is your original function, refined to ensure correct reading order.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    layout_counters = defaultdict(int)\n",
    "    reading_order = 0\n",
    "    line_map = {}\n",
    "    \n",
    "    # Your original loop structure is preserved.\n",
    "    for page in results:\n",
    "        # A line map is created for each page's blocks.\n",
    "        line_map.update({b['Id']: b for b in page['Blocks'] if b['BlockType'] == 'LINE'})\n",
    "        layout_blocks = [b for b in page['Blocks'] if b['BlockType'].startswith('LAYOUT')]\n",
    "\n",
    "        for block in layout_blocks:\n",
    "            layout_key = block['BlockType'].replace('LAYOUT_', '').capitalize()\n",
    "            layout_counters[layout_key] += 1\n",
    "            layout_label = f\"{layout_key} {layout_counters[layout_key]}\"\n",
    "\n",
    "            line_text = ''\n",
    "            for rel in block.get('Relationships', []):\n",
    "                if rel.get('Type') == 'CHILD':\n",
    "                    line_text = ' '.join(line_map.get(i, {}).get('Text', '') for i in rel.get('Ids', []) if i in line_map)\n",
    "\n",
    "            rows.append({\n",
    "                'Page number': block.get('Page', 1),\n",
    "                'Layout': layout_label,\n",
    "                'Text': line_text.strip(),\n",
    "                'Reading Order': reading_order,\n",
    "                'Confidence score % (Layout)': block.get('Confidence', 0.0)\n",
    "            })\n",
    "            reading_order += 1\n",
    "\n",
    "    layout_path = os.path.join(output_folder, 'layout.csv')\n",
    "    pd.DataFrame(rows).to_csv(layout_path, index=False)\n",
    "    print(f\"Saved layout to {layout_path}\")\n",
    "\n",
    "def save_figures(results, pdf_path, output_folder):\n",
    "    \"\"\"\n",
    "    REFINED: This function now correctly receives the data it needs to run.\n",
    "    \"\"\"\n",
    "    print(\"\\nExtracting and saving figures...\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening PDF '{pdf_path}': {e}\")\n",
    "        return\n",
    "\n",
    "    all_blocks = [block for page in results for block in page.get('Blocks', [])]\n",
    "    figure_blocks = [b for b in all_blocks if b.get('BlockType') == 'LAYOUT_FIGURE']\n",
    "\n",
    "    for i, block in enumerate(figure_blocks, 1):\n",
    "        try:\n",
    "            page_num = block.get('Page')\n",
    "            page = doc.load_page(page_num - 1)\n",
    "            box = block['Geometry']['BoundingBox']\n",
    "            \n",
    "            clip_rect = fitz.Rect(\n",
    "                box['Left'] * page.rect.width, box['Top'] * page.rect.height,\n",
    "                (box['Left'] + box['Width']) * page.rect.width,\n",
    "                (box['Top'] + box['Height']) * page.rect.height\n",
    "            )\n",
    "            \n",
    "            pix = page.get_pixmap(clip=clip_rect, dpi=200)\n",
    "            \n",
    "            output_path = os.path.join(output_folder, f\"figure_{i}.png\")\n",
    "            pix.save(output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not save figure_{i}.png. Error: {e}\")\n",
    "            \n",
    "    doc.close()\n",
    "    print(f\"Saved {len(figure_blocks)} figures to '{output_folder}'.\")\n",
    "\n",
    "# --- Example of how to run this function ---\n",
    "if __name__ == '__main__':\n",
    "    # Define the names of your main output folder and the subfolder\n",
    "    base_output_dir = \"output\"\n",
    "    document_folder = \"test_info_extract\"\n",
    "    pdf_file_path = \"test_info_extract.pdf\"\n",
    "    output_folder = os.path.join(base_output_dir, document_folder, \"figures\")\n",
    "\n",
    "    # 1. Build the path to the output folder where the JSON is located\n",
    "    #    This creates \"output/test_info_extract\"\n",
    "    output_folder_path = os.path.join(base_output_dir, document_folder)\n",
    "    \n",
    "    # 2. Build the full path to your raw JSON response file\n",
    "    json_file_path = os.path.join(output_folder_path, \"raw_textract_response.json\")\n",
    "\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        results_data = json.load(f)\n",
    "    \n",
    "    # 4. Call your refined function to create the CSV\n",
    "    save_layout(results_data, output_folder_path)\n",
    "    save_figures(results_data, pdf_file_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bcd6eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading layout CSV: 'output/test_info_extract/layout.csv'\n",
      "Finding figure images in: 'output/test_info_extract/figures'\n",
      "Found 12 figure files.\n",
      "Updating 'Figure 1' with text: 'figures\\figure_1.png'\n",
      "Updating 'Figure 2' with text: 'figures\\figure_2.png'\n",
      "Updating 'Figure 3' with text: 'figures\\figure_3.png'\n",
      "Updating 'Figure 4' with text: 'figures\\figure_4.png'\n",
      "Updating 'Figure 5' with text: 'figures\\figure_5.png'\n",
      "Updating 'Figure 6' with text: 'figures\\figure_6.png'\n",
      "Updating 'Figure 7' with text: 'figures\\figure_7.png'\n",
      "Updating 'Figure 8' with text: 'figures\\figure_8.png'\n",
      "Updating 'Figure 9' with text: 'figures\\figure_9.png'\n",
      "Updating 'Figure 10' with text: 'figures\\figure_10.png'\n",
      "Updating 'Figure 11' with text: 'figures\\figure_11.png'\n",
      "Updating 'Figure 12' with text: 'figures\\figure_12.png'\n",
      "\n",
      "Successfully created new CSV with integrated figure filenames: output/test_info_extract\\layout_with_figures.csv\n",
      "\n",
      "Creating Markdown file...\n",
      "Successfully created Markdown file: output/test_info_extract\\final_layout.md\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def create_markdown_file(dataframe, output_folder):\n",
    "    \"\"\"\n",
    "    Generates a markdown file from the final, corrected DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"\\nCreating Markdown file...\")\n",
    "    md_content = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        layout_type = str(row.get('Layout', '')).split(' ')[0]\n",
    "        text = str(row.get('Text', ''))\n",
    "\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        if layout_type == 'Title':\n",
    "            md_content.append(f\"# {text}\\n\")\n",
    "        elif layout_type == 'Header':\n",
    "            md_content.append(f\"## {text}\\n\")\n",
    "        elif layout_type == 'Figure':\n",
    "            # Assumes the 'Text' column contains the relative path to the figure\n",
    "            md_content.append(f\"![{text}]({text})\\n\")\n",
    "        else: # For 'Text', 'List', etc.\n",
    "            md_content.append(f\"{text}\\n\")\n",
    "    \n",
    "    # Save the final markdown content to a file\n",
    "    md_path = os.path.join(output_folder, 'final_layout.md')\n",
    "    with open(md_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\".join(md_content))\n",
    "    print(f\"Successfully created Markdown file: {md_path}\")\n",
    "\n",
    "\n",
    "def integrate_figures_and_create_outputs(csv_path, figures_folder):\n",
    "    \"\"\"\n",
    "    Reads a layout.csv, integrates figure filenames, saves the corrected CSV,\n",
    "    and then generates a corresponding markdown file.\n",
    "    \"\"\"\n",
    "    print(f\"Reading layout CSV: '{csv_path}'\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, na_filter=False)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_path}' was not found.\")\n",
    "        return\n",
    "\n",
    "    # 1. Find and sort all figure image files\n",
    "    print(f\"Finding figure images in: '{figures_folder}'\")\n",
    "    try:\n",
    "        figure_files = sorted(\n",
    "            [f for f in os.listdir(figures_folder) if f.startswith('figure_') and f.endswith('.png')],\n",
    "            key=lambda x: int(re.search(r'figure_(\\d+)\\.png', x).group(1))\n",
    "        )\n",
    "        print(f\"Found {len(figure_files)} figure files.\")\n",
    "    except (FileNotFoundError, AttributeError, TypeError):\n",
    "        print(f\"Error: Could not find or parse figure files in '{figures_folder}'.\")\n",
    "        return\n",
    "\n",
    "    # 2. Update the 'Text' column for each matched figure\n",
    "    figure_rows_indices = df[df['Layout'].str.startswith('Figure', na=False)].index\n",
    "    for i, df_index in enumerate(figure_rows_indices):\n",
    "        if i < len(figure_files):\n",
    "            # Create a relative path to the figure for the CSV\n",
    "            figure_path = os.path.join(os.path.basename(figures_folder), figure_files[i])\n",
    "            df.loc[df_index, 'Text'] = figure_path\n",
    "            print(f\"Updating '{df.loc[df_index, 'Layout']}' with text: '{figure_path}'\")\n",
    "\n",
    "    # 3. Save the updated DataFrame to a new CSV file\n",
    "    output_dir = os.path.dirname(csv_path) or '.'\n",
    "    output_csv_path = os.path.join(output_dir, 'layout_with_figures.csv')\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"\\nSuccessfully created new CSV with integrated figure filenames: {output_csv_path}\")\n",
    "\n",
    "    # 4. Generate the Markdown file from the now-corrected DataFrame\n",
    "    create_markdown_file(df, output_dir)\n",
    "\n",
    "\n",
    "# --- How to Run This Script ---\n",
    "if __name__ == '__main__':\n",
    "    # --- Configuration ---\n",
    "    \n",
    "    # 1. The path to the layout.csv file created by the previous script\n",
    "    CSV_PATH = 'output/test_info_extract/layout.csv'\n",
    "    \n",
    "    # 2. The path to the folder where your figures were saved\n",
    "    FIGURES_FOLDER_PATH = 'output/test_info_extract/figures'\n",
    "    \n",
    "    # ---------------------\n",
    "\n",
    "    integrate_figures_and_create_outputs(CSV_PATH, FIGURES_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc887b",
   "metadata": {},
   "source": [
    "## Summarize the data\n",
    "\n",
    "Create a summary of each element extracted from the PDF. This summary will be vectorized and used in the retrieval process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a06b3",
   "metadata": {},
   "source": [
    "### Text and Table summaries\n",
    "\n",
    "We don't need a multimodal model to generate the summaries of the tables and the text. I will use open source models available on Groq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b151050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "176d1557",
   "metadata": {},
   "source": [
    "### Image summaries\n",
    "\n",
    "We will use gpt-4o-mini to produce the image summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b365c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.25 requires langsmith<0.4,>=0.1.17, but you have langsmith 0.4.6 which is incompatible.\n",
      "langchain-community 0.3.23 requires langsmith<0.4,>=0.1.125, but you have langsmith 0.4.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65999ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('output/test_info_extract/layout_with_figures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad7900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page number</th>\n",
       "      <th>Layout</th>\n",
       "      <th>Text</th>\n",
       "      <th>Reading Order</th>\n",
       "      <th>Confidence score % (Layout)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Title 1</td>\n",
       "      <td>Home Energy Report: electricity</td>\n",
       "      <td>0</td>\n",
       "      <td>30.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 1</td>\n",
       "      <td>March report Account number: 954137 Service ad...</td>\n",
       "      <td>1</td>\n",
       "      <td>26.977539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 2</td>\n",
       "      <td>Dear JILL DOE, here is your usage analysis for...</td>\n",
       "      <td>2</td>\n",
       "      <td>84.863281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 3</td>\n",
       "      <td>Your electric use:</td>\n",
       "      <td>3</td>\n",
       "      <td>88.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 4</td>\n",
       "      <td>Above typical use</td>\n",
       "      <td>4</td>\n",
       "      <td>79.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 5</td>\n",
       "      <td>18% more than similar nearby homes</td>\n",
       "      <td>5</td>\n",
       "      <td>86.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Figure 1</td>\n",
       "      <td>figures\\figure_1.png</td>\n",
       "      <td>6</td>\n",
       "      <td>89.599609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 6</td>\n",
       "      <td>Nearby homes are defined as</td>\n",
       "      <td>7</td>\n",
       "      <td>82.373047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Figure 2</td>\n",
       "      <td>figures\\figure_2.png</td>\n",
       "      <td>8</td>\n",
       "      <td>66.259766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 7</td>\n",
       "      <td>Other homes with electricity</td>\n",
       "      <td>9</td>\n",
       "      <td>94.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Figure 3</td>\n",
       "      <td>figures\\figure_3.png</td>\n",
       "      <td>10</td>\n",
       "      <td>94.238281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 8</td>\n",
       "      <td>Homes within 9 km</td>\n",
       "      <td>11</td>\n",
       "      <td>91.943359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Figure 4</td>\n",
       "      <td>figures\\figure_4.png</td>\n",
       "      <td>12</td>\n",
       "      <td>96.386719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 9</td>\n",
       "      <td>Homes within +/- 300 sq. ft.</td>\n",
       "      <td>13</td>\n",
       "      <td>95.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 10</td>\n",
       "      <td>Nearby homes are based on fuel, distance and s...</td>\n",
       "      <td>14</td>\n",
       "      <td>95.361328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 11</td>\n",
       "      <td>Monthly savings tip: Do full laundry loads.</td>\n",
       "      <td>15</td>\n",
       "      <td>94.335938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 12</td>\n",
       "      <td>Waiting until you have a full load to run your...</td>\n",
       "      <td>16</td>\n",
       "      <td>95.751953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Figure 5</td>\n",
       "      <td>figures\\figure_5.png</td>\n",
       "      <td>17</td>\n",
       "      <td>91.162109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>Text 13</td>\n",
       "      <td>Watch this space for new ways to save energy e...</td>\n",
       "      <td>18</td>\n",
       "      <td>92.480469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>Footer 1</td>\n",
       "      <td>Turn over for more savings ideas.</td>\n",
       "      <td>19</td>\n",
       "      <td>72.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>Figure 6</td>\n",
       "      <td>figures\\figure_6.png</td>\n",
       "      <td>20</td>\n",
       "      <td>65.771484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>Title 2</td>\n",
       "      <td>Your top three tailored energy-saving tips</td>\n",
       "      <td>21</td>\n",
       "      <td>69.775391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>Text 14</td>\n",
       "      <td>Caulk windows and doors Save money and energy</td>\n",
       "      <td>22</td>\n",
       "      <td>80.761719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>Text 15</td>\n",
       "      <td>One of the biggest money-wasters in your home ...</td>\n",
       "      <td>23</td>\n",
       "      <td>87.207031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>Figure 7</td>\n",
       "      <td>figures\\figure_7.png</td>\n",
       "      <td>24</td>\n",
       "      <td>96.582031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>Text 16</td>\n",
       "      <td>Upgrade your refrigerator Look for an Energy S...</td>\n",
       "      <td>25</td>\n",
       "      <td>78.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>Text 17</td>\n",
       "      <td>Older model refrigerators are very inefficient...</td>\n",
       "      <td>26</td>\n",
       "      <td>95.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>Text 18</td>\n",
       "      <td>Adjust thermostat settings Biggest energy savi...</td>\n",
       "      <td>27</td>\n",
       "      <td>94.775391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>Figure 8</td>\n",
       "      <td>figures\\figure_8.png</td>\n",
       "      <td>28</td>\n",
       "      <td>96.777344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>Text 19</td>\n",
       "      <td>Set your smart thermostat to save more 78�� en...</td>\n",
       "      <td>29</td>\n",
       "      <td>74.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>Figure 9</td>\n",
       "      <td>figures\\figure_9.png</td>\n",
       "      <td>30</td>\n",
       "      <td>95.654297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>Figure 10</td>\n",
       "      <td>figures\\figure_10.png</td>\n",
       "      <td>31</td>\n",
       "      <td>90.966797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>Text 20</td>\n",
       "      <td>Save more this spring</td>\n",
       "      <td>32</td>\n",
       "      <td>70.556641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>Text 21</td>\n",
       "      <td>Reduce use and save money on your electric bil...</td>\n",
       "      <td>33</td>\n",
       "      <td>88.134766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>Figure 11</td>\n",
       "      <td>figures\\figure_11.png</td>\n",
       "      <td>34</td>\n",
       "      <td>95.019531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>Text 22</td>\n",
       "      <td>Evaluate your energy efficiency</td>\n",
       "      <td>35</td>\n",
       "      <td>51.367188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>Figure 12</td>\n",
       "      <td>figures\\figure_12.png</td>\n",
       "      <td>36</td>\n",
       "      <td>95.605469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>Text 23</td>\n",
       "      <td>Bring in the professionals! Assess your home's...</td>\n",
       "      <td>37</td>\n",
       "      <td>77.880859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Page number     Layout                                               Text  \\\n",
       "0             1    Title 1                    Home Energy Report: electricity   \n",
       "1             1     Text 1  March report Account number: 954137 Service ad...   \n",
       "2             1     Text 2  Dear JILL DOE, here is your usage analysis for...   \n",
       "3             1     Text 3                                 Your electric use:   \n",
       "4             1     Text 4                                  Above typical use   \n",
       "5             1     Text 5                 18% more than similar nearby homes   \n",
       "6             1   Figure 1                               figures\\figure_1.png   \n",
       "7             1     Text 6                        Nearby homes are defined as   \n",
       "8             1   Figure 2                               figures\\figure_2.png   \n",
       "9             1     Text 7                       Other homes with electricity   \n",
       "10            1   Figure 3                               figures\\figure_3.png   \n",
       "11            1     Text 8                                  Homes within 9 km   \n",
       "12            1   Figure 4                               figures\\figure_4.png   \n",
       "13            1     Text 9                       Homes within +/- 300 sq. ft.   \n",
       "14            1    Text 10  Nearby homes are based on fuel, distance and s...   \n",
       "15            1    Text 11        Monthly savings tip: Do full laundry loads.   \n",
       "16            1    Text 12  Waiting until you have a full load to run your...   \n",
       "17            1   Figure 5                               figures\\figure_5.png   \n",
       "18            1    Text 13  Watch this space for new ways to save energy e...   \n",
       "19            1   Footer 1                  Turn over for more savings ideas.   \n",
       "20            1   Figure 6                               figures\\figure_6.png   \n",
       "21            2    Title 2         Your top three tailored energy-saving tips   \n",
       "22            2    Text 14      Caulk windows and doors Save money and energy   \n",
       "23            2    Text 15  One of the biggest money-wasters in your home ...   \n",
       "24            2   Figure 7                               figures\\figure_7.png   \n",
       "25            2    Text 16  Upgrade your refrigerator Look for an Energy S...   \n",
       "26            2    Text 17  Older model refrigerators are very inefficient...   \n",
       "27            2    Text 18  Adjust thermostat settings Biggest energy savi...   \n",
       "28            2   Figure 8                               figures\\figure_8.png   \n",
       "29            2    Text 19  Set your smart thermostat to save more 78�� en...   \n",
       "30            2   Figure 9                               figures\\figure_9.png   \n",
       "31            2  Figure 10                              figures\\figure_10.png   \n",
       "32            2    Text 20                              Save more this spring   \n",
       "33            2    Text 21  Reduce use and save money on your electric bil...   \n",
       "34            2  Figure 11                              figures\\figure_11.png   \n",
       "35            2    Text 22                    Evaluate your energy efficiency   \n",
       "36            2  Figure 12                              figures\\figure_12.png   \n",
       "37            2    Text 23  Bring in the professionals! Assess your home's...   \n",
       "\n",
       "    Reading Order  Confidence score % (Layout)  \n",
       "0               0                    30.859375  \n",
       "1               1                    26.977539  \n",
       "2               2                    84.863281  \n",
       "3               3                    88.769531  \n",
       "4               4                    79.882812  \n",
       "5               5                    86.328125  \n",
       "6               6                    89.599609  \n",
       "7               7                    82.373047  \n",
       "8               8                    66.259766  \n",
       "9               9                    94.580078  \n",
       "10             10                    94.238281  \n",
       "11             11                    91.943359  \n",
       "12             12                    96.386719  \n",
       "13             13                    95.117188  \n",
       "14             14                    95.361328  \n",
       "15             15                    94.335938  \n",
       "16             16                    95.751953  \n",
       "17             17                    91.162109  \n",
       "18             18                    92.480469  \n",
       "19             19                    72.265625  \n",
       "20             20                    65.771484  \n",
       "21             21                    69.775391  \n",
       "22             22                    80.761719  \n",
       "23             23                    87.207031  \n",
       "24             24                    96.582031  \n",
       "25             25                    78.125000  \n",
       "26             26                    95.703125  \n",
       "27             27                    94.775391  \n",
       "28             28                    96.777344  \n",
       "29             29                    74.609375  \n",
       "30             30                    95.654297  \n",
       "31             31                    90.966797  \n",
       "32             32                    70.556641  \n",
       "33             33                    88.134766  \n",
       "34             34                    95.019531  \n",
       "35             35                    51.367188  \n",
       "36             36                    95.605469  \n",
       "37             37                    77.880859  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fab0de57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing contextual prompts for each figure...\n",
      "\n",
      "Processing 12 images with unique contexts...\n",
      "\n",
      "--- Figure Descriptions with Context ---\n",
      "File: figure_1.png\n",
      "Description: The image features a bar graph that compares energy usage in kilowatt-hours (kWh) among three categories:\n",
      "\n",
      "1. **You**: Represented by a large blue bar indicating a usage of 125 kWh.\n",
      "2. **Similar nearby homes**: Displayed as an orange bar, showing a usage of 103 kWh.\n",
      "3. **Efficient nearby homes**: Illustrated with a green bar, demonstrating the lowest usage at 49 kWh.\n",
      "\n",
      "Each category is clearly labeled, and the graph visually emphasizes that the energy consumption from \"You\" is 18% higher than that of \"Similar nearby homes.\" The layout allows for easy comparison among the three groups based on their respective energy usage.\n",
      "\n",
      "File: figure_2.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_3.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_4.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_5.png\n",
      "Description: The image features a woman holding a colorful chart or poster in one hand, while standing beside a washing machine. The woman has a hairstyle pulled back in a bun and is dressed in a purple top and orange pants. The washing machine is illustrated with a circular door, and there are basic details on the machine's interface. Overall, the image conveys a focus on laundry practices, likely aligning with energy-saving tips.\n",
      "\n",
      "File: figure_6.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_7.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_8.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_9.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_10.png\n",
      "Description: The image is a line graph that compares electricity usage in kilowatt-hours (kWh) over several months, specifically from April to March, among three categories: \"You,\" \"Similar Homes,\" and \"Efficient Homes.\"\n",
      "\n",
      "### Key Features:\n",
      "\n",
      "- **Axis**: \n",
      "  - The vertical axis (y-axis) represents electricity usage in kilowatt-hours (kWh), ranging from 0 to 200 kWh.\n",
      "  - The horizontal axis (x-axis) denotes the months from April to March.\n",
      "\n",
      "- **Data Lines**: \n",
      "  - **You**: Represented by a blue line. It shows varying usage levels throughout the months.\n",
      "  - **Similar Homes**: Indicated by an orange line, which fluctuates but generally stays above your usage.\n",
      "  - **Efficient Homes**: Shown with a green line, indicating lower electricity usage compared to both \"You\" and \"Similar Homes.\"\n",
      "\n",
      "### Trends:\n",
      "- The blue line for \"You\" shows peaks and dips over the months, indicating fluctuating electricity consumption.\n",
      "- The orange line for \"Similar Homes\" is consistently higher than the blue line, suggesting that the user's consumption is lower compared to similar homes.\n",
      "- The green line for \"Efficient Homes\" consistently remains the lowest, illustrating the least energy usage among the categories.\n",
      "\n",
      "Overall, the graph visually communicates how the user's electricity consumption compares with that of similar and more energy-efficient homes throughout the specified period.\n",
      "\n",
      "File: figure_11.png\n",
      "Description: icon\n",
      "\n",
      "File: figure_12.png\n",
      "Description: icon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"Encodes an image file to a base64 string.\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Image file not found at {image_path}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "# --- 1. Load the Layout Data ---\n",
    "csv_path = 'output/test_info_extract/layout_with_figures.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# --- 2. Prepare the Contextual Prompts and Image Data ---\n",
    "batch_input = []\n",
    "print(\"Preparing contextual prompts for each figure...\")\n",
    "for i, row in df.iterrows():\n",
    "    if str(row.get('Layout')).startswith('Figure'):\n",
    "        image_path = row['Text']\n",
    "        image_path = os.path.join(\"output\", \"test_info_extract\", image_path)  # Ensure the path is correct\n",
    "        # Get context from the row before the figure\n",
    "        text_before = df.loc[i - 1, 'Text'] if i > 0 else \"No text before.\"\n",
    "        \n",
    "        # Get context from the row after the figure\n",
    "        text_after = df.loc[i + 1, 'Text'] if i < len(df) - 1 else \"No text after.\"\n",
    "        \n",
    "        # Create a dynamic prompt with the context for this specific image\n",
    "        dynamic_prompt = f\"\"\"Describe the image in detail. It is part of a home energy report.\n",
    "\n",
    "CONTEXT BEFORE IMAGE: \"{text_before}\"\n",
    "CONTEXT AFTER IMAGE: \"{text_after}\"\n",
    "\n",
    "Based on the context above, analyze the image. Be specific about graphs, such as bar plots. If it's a simple icon with no data, just say 'icon' - no other explanation.\n",
    "\"\"\"\n",
    "        \n",
    "        # Encode the image and add it to our batch list\n",
    "        encoded_image = encode_image_to_base64(image_path)\n",
    "        if encoded_image:\n",
    "            batch_input.append({\n",
    "                \"image\": encoded_image,\n",
    "                \"prompt_text\": dynamic_prompt,\n",
    "                \"original_path\": os.path.basename(image_path) # For printing results\n",
    "            })\n",
    "\n",
    "# --- 3. Define the LangChain Prompt Template and Chain ---\n",
    "# The prompt template now includes a variable for our dynamic text\n",
    "messages = [\n",
    "    (\n",
    "        \"user\",\n",
    "        [\n",
    "            {\"type\": \"text\", \"text\": \"{prompt_text}\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image}\"},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# Initialize the model and create the chain\n",
    "# NOTE: Ensure your OPENAI_API_KEY environment variable is set\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# --- 4. Run the Batch Process and Print Results ---\n",
    "if batch_input:\n",
    "    print(f\"\\nProcessing {len(batch_input)} images with unique contexts...\")\n",
    "    \n",
    "    # The input is the list of dictionaries we prepared\n",
    "    image_summaries = chain.batch(batch_input, {\"max_concurrency\": 5})\n",
    "\n",
    "    print(\"\\n--- Figure Descriptions with Context ---\")\n",
    "    for i, summary in enumerate(image_summaries):\n",
    "        # Get the original filename from our input list for context\n",
    "        filename = batch_input[i]['original_path']\n",
    "        print(f\"File: {filename}\")\n",
    "        print(f\"Description: {summary}\\n\")\n",
    "else:\n",
    "    print(\"No figures found in the CSV to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19f81845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading layout CSV: 'output/test_info_extract/layout_with_figures.csv'\n",
      "Updated 'Figure 1' with new summary.\n",
      "Updated 'Figure 2' with new summary.\n",
      "Updated 'Figure 3' with new summary.\n",
      "Updated 'Figure 4' with new summary.\n",
      "Updated 'Figure 5' with new summary.\n",
      "Updated 'Figure 6' with new summary.\n",
      "Updated 'Figure 7' with new summary.\n",
      "Updated 'Figure 8' with new summary.\n",
      "Updated 'Figure 9' with new summary.\n",
      "Updated 'Figure 10' with new summary.\n",
      "Updated 'Figure 11' with new summary.\n",
      "Updated 'Figure 12' with new summary.\n",
      "\n",
      "Successfully created final CSV with summaries: output/test_info_extract\\layout_with_summaries_2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def update_csv_with_summaries(csv_path, summaries_list):\n",
    "    \"\"\"\n",
    "    Updates the 'Text' column of figure rows in a CSV with provided summaries.\n",
    "    \"\"\"\n",
    "    print(f\"Reading layout CSV: '{csv_path}'\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_path}' was not found.\")\n",
    "        return\n",
    "\n",
    "    # Find the indices of all rows where the 'Layout' is a figure\n",
    "    figure_indices = df[df['Layout'].str.startswith('Figure', na=False)].index.tolist()\n",
    "\n",
    "    # Check for a mismatch between the number of figures and summaries\n",
    "    if len(figure_indices) != len(summaries_list):\n",
    "        print(f\"Warning: Mismatch found!\")\n",
    "        print(f\"  - CSV has {len(figure_indices)} figure rows.\")\n",
    "        print(f\"  - You provided {len(summaries_list)} summaries.\")\n",
    "        print(\"  - The script will update as many as it can match.\")\n",
    "\n",
    "    # Iterate through the figure rows and update the 'Text' column\n",
    "    summary_counter = 0\n",
    "    for idx in figure_indices:\n",
    "        if summary_counter < len(summaries_list):\n",
    "            original_layout_label = df.loc[idx, 'Layout']\n",
    "            new_text = summaries_list[summary_counter]\n",
    "            \n",
    "            df.loc[idx, 'Text'] = new_text\n",
    "            print(f\"Updated '{original_layout_label}' with new summary.\")\n",
    "            \n",
    "            summary_counter += 1\n",
    "\n",
    "    # Save the final DataFrame to a new file\n",
    "    output_dir = os.path.dirname(csv_path) or '.'\n",
    "    output_path = os.path.join(output_dir, 'layout_with_summaries_2.csv')\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\nSuccessfully created final CSV with summaries: {output_path}\")\n",
    "\n",
    "# --- How to Run This Script ---\n",
    "if __name__ == '__main__':\n",
    "    # --- Configuration ---\n",
    "    \n",
    "    # 1. This is the path to your CSV file that has figure filenames\n",
    "    CSV_WITH_FIGURES_PATH = 'output/test_info_extract/layout_with_figures.csv'\n",
    "\n",
    "    # ---------------------\n",
    "\n",
    "    update_csv_with_summaries(CSV_WITH_FIGURES_PATH, image_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e934341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51cfad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21db86d8",
   "metadata": {},
   "source": [
    "### Create the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "afa025c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from chromadb) (2.11.4)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.1-cp310-cp310-win_amd64.whl.metadata (8.7 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from chromadb) (2.1.3)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.22.1-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.73.1-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from chromadb) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting jsonschema>=4.19.0 (from chromadb)\n",
      "  Using cached jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb)\n",
      "  Using cached tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.4)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (24.2.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.19.0->chromadb)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.19.0->chromadb)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.19.0->chromadb)\n",
      "  Downloading rpds_py-0.26.0-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.26.13)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: sympy in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.31.1)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (2.1.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl (19.5 MB)\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/19.5 MB 4.8 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.6/19.5 MB 4.2 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.4/19.5 MB 4.3 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 3.4/19.5 MB 4.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 4.2/19.5 MB 4.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 5.2/19.5 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 6.0/19.5 MB 4.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 7.1/19.5 MB 4.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 7.9/19.5 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 8.9/19.5 MB 4.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 9.4/19.5 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 10.0/19.5 MB 4.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 10.7/19.5 MB 4.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 11.5/19.5 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 12.6/19.5 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 13.4/19.5 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 14.4/19.5 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 15.2/19.5 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 16.3/19.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 17.0/19.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 17.8/19.5 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 18.9/19.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.5/19.5 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading grpcio-1.73.1-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.8/4.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.8/4.3 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.9/4.3 MB 4.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.7/4.3 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 4.5 MB/s eta 0:00:00\n",
      "Using cached jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading mmh3-5.1.0-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.22.1-cp310-cp310-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.7 MB 5.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.8/12.7 MB 5.0 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.9/12.7 MB 5.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.7/12.7 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.7/12.7 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.0/12.7 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.8/12.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.6/12.7 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.9/12.7 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.0/12.7 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.7 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.7 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading pybase64-1.4.1-cp310-cp310-win_amd64.whl (36 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.26.0-cp310-cp310-win_amd64.whl (231 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Downloading watchfiles-1.1.0-cp310-cp310-win_amd64.whl (292 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=4d8f2453efc41f8957f07bbc6cab295df469dc0fae1234fdc8fc5fb18b7b1083\n",
      "  Stored in directory: c:\\users\\alister\\appdata\\local\\pip\\cache\\wheels\\e1\\26\\51\\d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, websockets, websocket-client, tomli, shellingham, rpds-py, pyreadline3, pyproject_hooks, pybase64, pyasn1, protobuf, overrides, oauthlib, mmh3, mdurl, importlib-resources, httptools, grpcio, click, cachetools, bcrypt, backoff, watchfiles, uvicorn, rsa, requests-oauthlib, referencing, pyasn1-modules, posthog, opentelemetry-proto, opentelemetry-api, markdown-it-py, humanfriendly, googleapis-common-protos, build, tokenizers, rich, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, jsonschema-specifications, google-auth, coloredlogs, typer, opentelemetry-sdk, onnxruntime, kubernetes, jsonschema, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "Successfully installed backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chromadb-1.0.15 click-8.2.1 coloredlogs-15.0.1 durationpy-0.10 flatbuffers-25.2.10 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.73.1 httptools-0.6.4 humanfriendly-10.0 importlib-resources-6.5.2 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 kubernetes-33.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 oauthlib-3.3.1 onnxruntime-1.22.1 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 overrides-7.7.0 posthog-5.4.0 protobuf-6.31.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 referencing-0.36.2 requests-oauthlib-2.0.0 rich-14.0.0 rpds-py-0.26.0 rsa-4.9.1 shellingham-1.5.4 tokenizers-0.21.2 tomli-2.2.1 typer-0.16.0 uvicorn-0.35.0 watchfiles-1.1.0 websocket-client-1.8.0 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb94bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from 'output/test_info_extract/layout_with_summaries_2.csv'...\n",
      "Creating custom text chunks...\n",
      "Created 5 chunks based on a 1000 character limit.\n",
      "\n",
      "Embedding and storing documents in Chroma collection: 'multimodal_rag_collection'...\n",
      "\n",
      "Successfully created and stored embeddings in ChromaDB.\n",
      "\n",
      "--- Example Similarity Search for: 'What was the energy usage compared to neighbors?' ---\n",
      "Figure 1: The image features a bar graph that compares energy usage in kilowatt-hours (kWh) among three categories:\n",
      "\n",
      "1. **You**: Represented by a large blue bar indicating a usage of 125 kWh.\n",
      "2. **Similar nearby homes**: Displayed as an orange bar, showing a usage of 103 kWh.\n",
      "3. **Efficient nearby homes**: Illustrated with a green bar, demonstrating the lowest usage at 49 kWh.\n",
      "\n",
      "Each category is clearly labeled, and the graph visually emphasizes that the energy consumption from \"You\" is 18% higher than that of \"Similar nearby homes.\" The layout allows for easy comparison among the three groups based on their respective energy usage.\n",
      "------------------------------\n",
      "Title 1: Home Energy Report: electricity\n",
      "Text 1: March report Account number: 954137 Service address: 1627 Tulip Lane\n",
      "Text 2: Dear JILL DOE, here is your usage analysis for March.\n",
      "Text 3: Your electric use:\n",
      "Text 4: Above typical use\n",
      "Text 5: 18% more than similar nearby homes\n",
      "Figure 1: The image features a bar graph that compares energy usage in kilowatt-hours (kWh) among three categories:\n",
      "\n",
      "1. **You**: Represented by a large blue bar indicating a usage of 125 kWh.\n",
      "2. **Similar nearby homes**: Displayed as an orange bar, showing a usage of 103 kWh.\n",
      "3. **Efficient nearby homes**: Illustrated with a green bar, demonstrating the lowest usage at 49 kWh.\n",
      "\n",
      "Each category is clearly labeled, and the graph visually emphasizes that the energy consumption from \"You\" is 18% higher than that of \"Similar nearby homes.\" The layout allows for easy comparison among the three groups based on their respective energy usage.\n",
      "Text 6: Nearby homes are defined as\n",
      "Figure 2: icon\n",
      "------------------------------\n",
      "Text 7: Other homes with electricity\n",
      "Figure 3: icon\n",
      "Text 8: Homes within 9 km\n",
      "Figure 4: icon\n",
      "Text 9: Homes within +/- 300 sq. ft.\n",
      "Text 10: Nearby homes are based on fuel, distance and size. Square footage is collected from public information sources. Efficient nearby homes are the top 15 per cent efficient of similar-sized homes nearby.\n",
      "Text 11: Monthly savings tip: Do full laundry loads.\n",
      "Text 12: Waiting until you have a full load to run your laundry can save up to 6% of your energy use.\n",
      "Figure 5: The image features a woman holding a colorful chart or poster in one hand, while standing beside a washing machine. The woman has a hairstyle pulled back in a bun and is dressed in a purple top and orange pants. The washing machine is illustrated with a circular door, and there are basic details on the machine's interface. Overall, the image conveys a focus on laundry practices, likely aligning with energy-saving tips.\n",
      "Text 13: Watch this space for new ways to save energy each month.\n",
      "------------------------------\n",
      "Title 1: Home Energy Report: electricity\n",
      "Text 1: March report Account number: 954137 Service address: 1627 Tulip Lane\n",
      "Text 2: Dear JILL DOE, here is your usage analysis for March.\n",
      "Text 3: Your electric use:\n",
      "Text 4: Above typical use\n",
      "Text 5: 18% more than similar nearby homes\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables (for OPENAI_API_KEY)\n",
    "load_dotenv()\n",
    "\n",
    "def create_and_store_chunks(csv_path, collection_name, max_chars=500):\n",
    "    \"\"\"\n",
    "    Reads a layout CSV, creates custom chunks, and stores their\n",
    "    embeddings in a Chroma vector store.\n",
    "    \"\"\"\n",
    "    # --- 1. Load and sort the data ---\n",
    "    print(f\"Loading data from '{csv_path}'...\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, na_filter=False)\n",
    "        df_sorted = df.sort_values(by='Reading Order').reset_index(drop=True)\n",
    "    except (FileNotFoundError, KeyError) as e:\n",
    "        print(f\"Error loading or sorting CSV: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Create chunks with your custom logic ---\n",
    "    print(\"Creating custom text chunks...\")\n",
    "    chunks = []\n",
    "    current_chunk_text = \"\"\n",
    "    for index, row in df_sorted.iterrows():\n",
    "        text_to_add = f\"{row['Layout']}: {row['Text']}\"\n",
    "\n",
    "        if not current_chunk_text:\n",
    "            current_chunk_text = text_to_add\n",
    "            continue\n",
    "\n",
    "        if len(current_chunk_text) + len(text_to_add) + 1 > max_chars:\n",
    "            chunks.append(current_chunk_text)\n",
    "            current_chunk_text = text_to_add\n",
    "        else:\n",
    "            current_chunk_text += \"\\n\" + text_to_add\n",
    "\n",
    "    if current_chunk_text:\n",
    "        chunks.append(current_chunk_text)\n",
    "\n",
    "    print(f\"Created {len(chunks)} chunks based on a {max_chars} character limit.\")\n",
    "\n",
    "    # --- 3. Convert chunks to LangChain Document objects ---\n",
    "    documents_to_embed = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "    # --- 4. Embed and store the documents in ChromaDB ---\n",
    "    print(f\"\\nEmbedding and storing documents in Chroma collection: '{collection_name}'...\")\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents_to_embed,\n",
    "        embedding=OpenAIEmbeddings(),\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "\n",
    "    print(\"\\nSuccessfully created and stored embeddings in ChromaDB.\")\n",
    "    return vectorstore\n",
    "\n",
    "# --- How to Run ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. Path to your final CSV file with summaries\n",
    "    CSV_PATH = 'output/test_info_extract/layout_with_summaries_2.csv'\n",
    "    \n",
    "    # 2. Name for your ChromaDB collection\n",
    "    COLLECTION_NAME = \"multimodal_rag_collection\"\n",
    "\n",
    "    # 3. Create the chunks, embed them, and store them\n",
    "    vector_store = create_and_store_chunks(\n",
    "        csv_path=CSV_PATH,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        max_chars=1000\n",
    "    )\n",
    "\n",
    "    # You can now use the 'vector_store' object to run similarity searches\n",
    "    if vector_store:\n",
    "        query = \"What was the energy usage compared to neighbors?\"\n",
    "        results = vector_store.similarity_search(query)\n",
    "        print(f\"\\n--- Example Similarity Search for: '{query}' ---\")\n",
    "        for doc in results:\n",
    "            print(doc.page_content)\n",
    "            print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "518dc3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Using cached rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\alister\\anaconda3\\envs\\myenv\\lib\\site-packages (from rank_bm25) (2.1.3)\n",
      "Using cached rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27d68da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 38 documents.\n",
      "\n",
      "Successfully built the MultiVectorRetriever and EnsembleRetriever.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import base64\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Encode image ---\n",
    "def encode_image_base64(path):\n",
    "    \"\"\"\n",
    "    CORRECTED: This function now expects a full, valid path.\n",
    "    \"\"\"\n",
    "    if pd.isna(path) or not os.path.exists(path):\n",
    "        print(f\"Warning: Image file not found at '{path}'.\")\n",
    "        return \"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# --- 1. Load CSVs ---\n",
    "df_full = pd.read_csv(\"output/test_info_extract/layout_with_figures.csv\")\n",
    "df_sum = pd.read_csv(\"output/test_info_extract/layout_with_summaries_2.csv\")\n",
    "assert len(df_full) == len(df_sum), \"Row counts must match\"\n",
    "\n",
    "# --- 2. Build Parent & Child Docs (Corrected Loop) ---\n",
    "parent_docs, child_docs, ids = [], [], []\n",
    "\n",
    "# Define the base directory where your output is stored\n",
    "base_dir = \"output/test_info_extract\"\n",
    "\n",
    "for full, summ in zip(df_full.itertuples(), df_sum.itertuples()):\n",
    "    doc_id = str(uuid.uuid4())\n",
    "    image_str = \"\"  # CORRECTION: Initialize image_str for every row\n",
    "\n",
    "    # Check if the row represents a figure\n",
    "    if hasattr(full, 'Layout') and isinstance(full.Layout, str) and full.Layout.startswith(\"Figure\"):\n",
    "        if hasattr(full, 'Text') and pd.notna(full.Text):\n",
    "            \n",
    "            # CORRECTION: Construct the full, correct path to the image file\n",
    "            # The 'Text' column contains a relative path like 'figures\\figure_1.png'\n",
    "            relative_image_path = full.Text.replace(\"\\\\\", \"/\") # Normalize path separators\n",
    "            figure_path = os.path.join(base_dir, relative_image_path)\n",
    "            \n",
    "            image_base64 = encode_image_base64(figure_path)\n",
    "            \n",
    "            if image_base64:\n",
    "                image_str = f\"\\n[Image base64]: {image_base64}\"\n",
    "\n",
    "    # For figure rows, use the summary text. For text rows, use the original text.\n",
    "    parent_text_content = summ.Text if \"Figure\" in full.Layout else full.Text\n",
    "    summary_text_content = summ.Text\n",
    "\n",
    "    # Construct the final content strings\n",
    "    parent_text = f\"{full.Layout}: {parent_text_content}{image_str}\"\n",
    "    summary_text = f\"{summ.Layout}: {summary_text_content}{image_str}\"\n",
    "\n",
    "    parent_docs.append(Document(page_content=parent_text, metadata={\"doc_id\": doc_id}))\n",
    "    child_docs.append(Document(page_content=summary_text, metadata={\"doc_id\": doc_id}))\n",
    "    ids.append(doc_id)\n",
    "\n",
    "print(f\"Processed {len(parent_docs)} documents.\")\n",
    "\n",
    "# --- 3. Vectorstore + BM25 ---\n",
    "emb = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(collection_name=\"multimodal_rag_summaries\", embedding_function=emb)\n",
    "vectorstore.add_documents(child_docs)\n",
    "\n",
    "bm25 = BM25Retriever.from_documents(child_docs)\n",
    "bm25.k = 5\n",
    "\n",
    "semantic = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "hybrid = EnsembleRetriever(retrievers=[bm25, semantic], weights=[0.5, 0.5])\n",
    "\n",
    "# --- 4. MultiVectorRetriever ---\n",
    "store = InMemoryStore()\n",
    "store.mset(list(zip(ids, parent_docs)))\n",
    "\n",
    "multi_retriever = MultiVectorRetriever(vectorstore=vectorstore, docstore=store, id_key=\"doc_id\")\n",
    "\n",
    "print(\"\\nSuccessfully built the MultiVectorRetriever and EnsembleRetriever.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "71844242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded output/test_info_extract\\figures/figure_1.png and generated pre-signed URL.\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_2.png and generated pre-signed URL.\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_3.png and generated pre-signed URL.\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_4.png and generated pre-signed URL.\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_5.png and generated pre-signed URL.\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_6.png and generated pre-signed URL.\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_7.png and generated pre-signed URL.\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_8.png and generated pre-signed URL.\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_9.png and generated pre-signed URL.\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_10.png and generated pre-signed URL.\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_11.png and generated pre-signed URL.\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_12.png and generated pre-signed URL.\n",
      "\n",
      "Processed 38 documents.\n",
      "\n",
      "Successfully built the MultiVectorRetriever and EnsembleRetriever.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- S3 Upload Function (Corrected with Pre-signed URL) ---\n",
    "def upload_image_to_s3(local_path, bucket_name, s3_client):\n",
    "    \"\"\"\n",
    "    Uploads a local image file to an S3 bucket and returns a pre-signed URL\n",
    "    that is valid for 1 hour.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(local_path):\n",
    "        print(f\"Warning: Image file not found at '{local_path}'.\")\n",
    "        return \"\"\n",
    "    \n",
    "    s3_key = f\"figures/{os.path.basename(local_path)}\"\n",
    "    \n",
    "    try:\n",
    "        s3_client.upload_file(local_path, bucket_name, s3_key)\n",
    "        \n",
    "        # --- THIS IS THE FIX ---\n",
    "        # Generate a temporary, secure URL instead of a public one.\n",
    "        # The URL will be valid for 3600 seconds (1 hour).\n",
    "        url = s3_client.generate_presigned_url(\n",
    "            'get_object',\n",
    "            Params={'Bucket': bucket_name, 'Key': s3_key},\n",
    "            ExpiresIn=3600\n",
    "        )\n",
    "        print(f\"Successfully uploaded {local_path} and generated pre-signed URL.\")\n",
    "        return url\n",
    "    except Exception as e:\n",
    "        print(f\"Error during S3 operation: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# --- 1. Load CSVs and Initialize S3 Client ---\n",
    "df_full = pd.read_csv(\"output/test_info_extract/layout_with_figures.csv\")\n",
    "df_sum = pd.read_csv(\"output/test_info_extract/layout_with_summaries_2.csv\")\n",
    "assert len(df_full) == len(df_sum), \"Row counts must match\"\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = os.getenv(\"AWS_BUCKET_NAME\")\n",
    "if not bucket_name:\n",
    "    raise ValueError(\"AWS_BUCKET_NAME not set in .env file.\")\n",
    "\n",
    "# --- 2. Build Parent & Child Docs with S3 URLs ---\n",
    "parent_docs, child_docs, ids = [], [], []\n",
    "base_dir = \"output/test_info_extract\"\n",
    "\n",
    "for full, summ in zip(df_full.itertuples(), df_sum.itertuples()):\n",
    "    doc_id = str(uuid.uuid4())\n",
    "    image_url_str = \"\"\n",
    "\n",
    "    if hasattr(full, 'Layout') and isinstance(full.Layout, str) and full.Layout.startswith(\"Figure\"):\n",
    "        if hasattr(full, 'Text') and pd.notna(full.Text):\n",
    "            relative_image_path = full.Text.replace(\"\\\\\", \"/\")\n",
    "            figure_path = os.path.join(base_dir, relative_image_path)\n",
    "            \n",
    "            image_url = upload_image_to_s3(figure_path, bucket_name, s3_client)\n",
    "            \n",
    "            if image_url:\n",
    "                image_url_str = f\"\\n[Image URL]: {image_url}\"\n",
    "\n",
    "    parent_text_content = summ.Text if \"Figure\" in full.Layout else full.Text\n",
    "    summary_text_content = summ.Text\n",
    "\n",
    "    parent_text = f\"{full.Layout}: {parent_text_content}{image_url_str}\"\n",
    "    summary_text = f\"{summ.Layout}: {summary_text_content}\"\n",
    "\n",
    "    parent_docs.append(Document(page_content=parent_text, metadata={\"doc_id\": doc_id}))\n",
    "    child_docs.append(Document(page_content=summary_text, metadata={\"doc_id\": doc_id}))\n",
    "    ids.append(doc_id)\n",
    "\n",
    "print(f\"\\nProcessed {len(parent_docs)} documents.\")\n",
    "\n",
    "# --- 3. Vectorstore + BM25 ---\n",
    "emb = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(collection_name=\"multimodal_rag_s3\", embedding_function=emb)\n",
    "vectorstore.add_documents(child_docs)\n",
    "\n",
    "bm25 = BM25Retriever.from_documents(child_docs)\n",
    "bm25.k = 5\n",
    "\n",
    "semantic = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "hybrid = EnsembleRetriever(retrievers=[bm25, semantic], weights=[0.5, 0.5])\n",
    "\n",
    "# --- 4. MultiVectorRetriever ---\n",
    "store = InMemoryStore()\n",
    "store.mset(list(zip(ids, parent_docs)))\n",
    "\n",
    "multi_retriever = MultiVectorRetriever(vectorstore=vectorstore, docstore=store, id_key=\"doc_id\")\n",
    "\n",
    "print(\"\\nSuccessfully built the MultiVectorRetriever and EnsembleRetriever.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7446974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "from base64 import b64decode\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "# --- Load environment and data ---\n",
    "load_dotenv()\n",
    "\n",
    "# --- Utility: Convert image file to base64-encoded string ---\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# --- Hybrid search logic with parent document fetching ---\n",
    "def hybrid_search_with_parent(query: str, k: int = 5):\n",
    "    child_hits = hybrid.invoke(query)\n",
    "    seen_ids = []\n",
    "    for doc in child_hits:\n",
    "        doc_id = doc.metadata.get(\"doc_id\")\n",
    "        if doc_id and doc_id not in seen_ids:\n",
    "            seen_ids.append(doc_id)\n",
    "        if len(seen_ids) >= k:\n",
    "            break\n",
    "    parent_hits = store.mget(seen_ids)\n",
    "    return [doc for doc in parent_hits if doc is not None]\n",
    "\n",
    "retriever = RunnableLambda(lambda q: hybrid_search_with_parent(q))\n",
    "\n",
    "# --- Parser: split base64-encoded images from regular text ---\n",
    "def parse_docs(docs):\n",
    "    b64, text = [], []\n",
    "    for doc in docs:\n",
    "        try:\n",
    "            b64decode(doc.page_content)\n",
    "            b64.append(doc.page_content)\n",
    "        except Exception:\n",
    "            text.append(doc)\n",
    "    return {\"images\": b64, \"texts\": text}\n",
    "\n",
    "# --- Prompt builder: includes image_urls from base64-encoded strings ---\n",
    "def build_prompt(kwargs):\n",
    "    docs_by_type = kwargs[\"context\"]\n",
    "    user_question = kwargs[\"question\"]\n",
    "    context_text = \"\".join(doc.page_content for doc in docs_by_type[\"texts\"])\n",
    "\n",
    "    prompt_template = f\"\"\"\n",
    "    Answer the question based only on the following context, which can include text, tables, and images.\n",
    "    Context: {context_text}\n",
    "    Question: {user_question}\n",
    "    \"\"\"\n",
    "    prompt_content = [{\"type\": \"text\", \"text\": prompt_template}]\n",
    "    for image in docs_by_type[\"images\"]:\n",
    "        prompt_content.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "        })\n",
    "    print(ChatPromptTemplate.from_messages([HumanMessage(content=prompt_content)]))\n",
    "    return ChatPromptTemplate.from_messages([HumanMessage(content=prompt_content)])\n",
    "\n",
    "# --- Main RAG Chain ---\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(parse_docs),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(build_prompt)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# --- Optional: Chain with sources ---\n",
    "chain_with_sources = {\n",
    "    \"context\": retriever | RunnableLambda(parse_docs),\n",
    "    \"question\": RunnablePassthrough(),\n",
    "} | RunnablePassthrough().assign(\n",
    "    response=RunnableLambda(build_prompt) | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1527adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] input_types={} partial_variables={} messages=[HumanMessage(content=[{'type': 'text', 'text': '\\n    Answer the question based only on the following context, which can include text, tables, and images.\\n    Context: Text 22: Evaluate your energy efficiencyText 12: Waiting until you have a full load to run your laundry can save up to 6% of your energy use.Text 13: Watch this space for new ways to save energy each month.\\n    Question: How much energy did I consume compared to my neighbors?\\n    '}, {'type': 'image_url', 'image_url': {'url': 'data:image/jpeg;base64,Figure 10: The image is a line graph that compares electricity usage in kilowatt-hours (kWh) over several months, specifically from April to March, among three categories: \"You,\" \"Similar Homes,\" and \"Efficient Homes.\"\\r\\n\\r\\n### Key Features:\\r\\n\\r\\n- **Axis**: \\r\\n  - The vertical axis (y-axis) represents electricity usage in kilowatt-hours (kWh), ranging from 0 to 200 kWh.\\r\\n  - The horizontal axis (x-axis) denotes the months from April to March.\\r\\n\\r\\n- **Data Lines**: \\r\\n  - **You**: Represented by a blue line. It shows varying usage levels throughout the months.\\r\\n  - **Similar Homes**: Indicated by an orange line, which fluctuates but generally stays above your usage.\\r\\n  - **Efficient Homes**: Shown with a green line, indicating lower electricity usage compared to both \"You\" and \"Similar Homes.\"\\r\\n\\r\\n### Trends:\\r\\n- The blue line for \"You\" shows peaks and dips over the months, indicating fluctuating electricity consumption.\\r\\n- The orange line for \"Similar Homes\" is consistently higher than the blue line, suggesting that the user\\'s consumption is lower compared to similar homes.\\r\\n- The green line for \"Efficient Homes\" consistently remains the lowest, illustrating the least energy usage among the categories.\\r\\n\\r\\nOverall, the graph visually communicates how the user\\'s electricity consumption compares with that of similar and more energy-efficient homes throughout the specified period.\\n[Image URL]: https://capstone-bucket-alister.s3.amazonaws.com/figures/figure_10.png?AWSAccessKeyId=AKIAWQUOZ4236TFSWCUI&Signature=S0fWddfTUXiMZO9c2vYPcKbFY%2Fo%3D&Expires=1752744063'}}], additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_format'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow much energy did I consume compared to my neighbors?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Or with sources:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3046\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3044\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3045\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3046\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3047\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3048\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    374\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    375\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    379\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    380\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    381\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    382\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    383\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    384\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    385\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    386\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    387\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    388\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    961\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    962\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 782\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    783\u001b[0m                 m,\n\u001b[0;32m    784\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    785\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    786\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    787\u001b[0m             )\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1028\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1029\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1030\u001b[0m     )\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:1131\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1087\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1085\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m   1086\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\openai\\_base_client.py:1256\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1244\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1252\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1253\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1254\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1255\u001b[0m     )\n\u001b[1;32m-> 1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\openai\\_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1043\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1044\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_format'}}"
     ]
    }
   ],
   "source": [
    "query = \"How much energy did I consume compared to my neighbors?\"\n",
    "response = chain.invoke(query)\n",
    "print(response)\n",
    "\n",
    "# Or with sources:\n",
    "full_result = chain_with_sources.invoke(query)\n",
    "print(full_result[\"response\"])\n",
    "print(full_result[\"context\"])  # includes both base64 images and text Document objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "08f8b1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing documents and uploading figures to S3...\n",
      "\n",
      "Retriever setup complete.\n",
      "\n",
      "--- QUERY ---\n",
      "Show me the graph comparing my energy usage to my neighbors and describe it.\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "The first graph is a bar graph comparing energy usage in kilowatt-hours (kWh) among three categories:\n",
      "\n",
      "1. **You**: Represented by a large blue bar indicating a usage of 125 kWh.\n",
      "2. **Similar nearby homes**: Displayed as an orange bar, showing a usage of 103 kWh.\n",
      "3. **Efficient nearby homes**: Illustrated with a green bar, demonstrating the lowest usage at 49 kWh.\n",
      "\n",
      "The graph emphasizes that your energy consumption is 18% higher than that of similar nearby homes.\n",
      "\n",
      "The second graph is a line graph showing electricity usage over several months (April to March) among the same three categories:\n",
      "\n",
      "- **You**: Represented by a blue line, showing varying usage levels throughout the months.\n",
      "- **Similar Homes**: Indicated by an orange line, generally staying above your usage.\n",
      "- **Efficient Homes**: Shown with a green line, consistently indicating the lowest electricity usage.\n",
      "\n",
      "The graph visually communicates how your electricity consumption compares with that of similar and more energy-efficient homes throughout the year.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import boto3 # Added for S3\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- S3 Upload Function ---\n",
    "def upload_image_to_s3(local_path, bucket_name, s3_client):\n",
    "    \"\"\"\n",
    "    Uploads a local image file to S3 and returns a pre-signed URL.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(local_path):\n",
    "        print(f\"Warning: Image file not found at '{local_path}'.\")\n",
    "        return \"\"\n",
    "    \n",
    "    s3_key = f\"figures/{os.path.basename(local_path)}\"\n",
    "    \n",
    "    try:\n",
    "        s3_client.upload_file(local_path, bucket_name, s3_key)\n",
    "        # Generate a temporary, secure URL valid for 1 hour\n",
    "        url = s3_client.generate_presigned_url(\n",
    "            'get_object',\n",
    "            Params={'Bucket': bucket_name, 'Key': s3_key},\n",
    "            ExpiresIn=3600\n",
    "        )\n",
    "        return url\n",
    "    except Exception as e:\n",
    "        print(f\"Error during S3 upload: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# --- 1. Load CSVs and Initialize S3 ---\n",
    "df_full = pd.read_csv(\"output/test_info_extract/layout_with_figures.csv\")\n",
    "df_sum = pd.read_csv(\"output/test_info_extract/layout_with_summaries_2.csv\")\n",
    "assert len(df_full) == len(df_sum), \"Row counts must match\"\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = os.getenv(\"AWS_BUCKET_NAME\")\n",
    "if not bucket_name:\n",
    "    raise ValueError(\"AWS_BUCKET_NAME not set in .env file.\")\n",
    "\n",
    "# --- 2. Build Parent & Child Docs with S3 URLs ---\n",
    "parent_docs, child_docs, ids = [], [], []\n",
    "base_dir = \"output/test_info_extract\"\n",
    "\n",
    "print(\"Processing documents and uploading figures to S3...\")\n",
    "for full, summ in zip(df_full.itertuples(), df_sum.itertuples()):\n",
    "    doc_id = str(uuid.uuid4())\n",
    "    image_url_str = \"\"\n",
    "\n",
    "    if hasattr(full, 'Layout') and isinstance(full.Layout, str) and full.Layout.startswith(\"Figure\"):\n",
    "        if hasattr(full, 'Text') and pd.notna(full.Text):\n",
    "            relative_image_path = full.Text.replace(\"\\\\\", \"/\")\n",
    "            figure_path = os.path.join(base_dir, relative_image_path)\n",
    "            \n",
    "            # Upload image and get the URL\n",
    "            image_url = upload_image_to_s3(figure_path, bucket_name, s3_client)\n",
    "            \n",
    "            if image_url:\n",
    "                # Use a clear marker for the URL\n",
    "                image_url_str = f\"\\n[IMAGE_URL_START]\\n{image_url}\\n[IMAGE_URL_END]\"\n",
    "\n",
    "    parent_text_content = summ.Text if \"Figure\" in full.Layout else full.Text\n",
    "    summary_text_content = summ.Text\n",
    "\n",
    "    parent_text = f\"{full.Layout}: {parent_text_content}{image_url_str}\"\n",
    "    summary_text = f\"{summ.Layout}: {summary_text_content}\" # Searchable summary is text-only\n",
    "\n",
    "    parent_docs.append(Document(page_content=parent_text, metadata={\"doc_id\": doc_id}))\n",
    "    child_docs.append(Document(page_content=summary_text, metadata={\"doc_id\": doc_id}))\n",
    "    ids.append(doc_id)\n",
    "\n",
    "# --- 3. Setup Retrievers (Unchanged) ---\n",
    "emb = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(collection_name=\"multimodal_rag_s3_final\", embedding_function=emb)\n",
    "vectorstore.add_documents(child_docs)\n",
    "\n",
    "bm25 = BM25Retriever.from_documents(child_docs)\n",
    "bm25.k = 5\n",
    "semantic = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "hybrid = EnsembleRetriever(retrievers=[bm25, semantic], weights=[0.5, 0.5])\n",
    "\n",
    "store = InMemoryStore()\n",
    "store.mset(list(zip(ids, parent_docs)))\n",
    "retriever = MultiVectorRetriever(vectorstore=vectorstore, docstore=store, id_key=\"doc_id\")\n",
    "print(\"\\nRetriever setup complete.\")\n",
    "\n",
    "# --- 4. Define the RAG Chain with Corrected Parsers ---\n",
    "\n",
    "def parse_docs_for_urls(docs):\n",
    "    \"\"\"\n",
    "    Parses retrieved documents by looking for the explicit image URL marker.\n",
    "    \"\"\"\n",
    "    image_urls = []\n",
    "    text_content = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        parts = doc.page_content.split(\"[IMAGE_URL_START]\")\n",
    "        text_content.append(parts[0])\n",
    "        \n",
    "        if len(parts) > 1:\n",
    "            url_part = parts[1].split(\"[IMAGE_URL_END]\")[0].strip()\n",
    "            image_urls.append(url_part)\n",
    "            \n",
    "    return {\"images\": image_urls, \"texts\": text_content}\n",
    "\n",
    "def build_prompt_with_urls(inputs):\n",
    "    \"\"\"\n",
    "    Dynamically builds the prompt, adding image_url dicts if URLs are present.\n",
    "    \"\"\"\n",
    "    context = inputs[\"context\"]\n",
    "    question = inputs[\"question\"]\n",
    "    \n",
    "    context_text = \"\\n\".join(context['texts']).strip()\n",
    "    \n",
    "    prompt_content = [{\n",
    "        \"type\": \"text\",\n",
    "        \"text\": f\"\"\"Answer the question based only on the following context, which can include text and images.\n",
    "\n",
    "Context:\n",
    "---\n",
    "{context_text}\n",
    "---\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "    }]\n",
    "    \n",
    "    # Add image URLs if any were found\n",
    "    for url in context[\"images\"]:\n",
    "        prompt_content.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": url}, # Directly use the URL\n",
    "        })\n",
    "        \n",
    "    return [HumanMessage(content=prompt_content)]\n",
    "\n",
    "# --- Main RAG Chain ---\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(parse_docs_for_urls),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(build_prompt_with_urls)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Show me the graph comparing my energy usage to my neighbors and describe it.\"\n",
    "    answer = chain.invoke(query)\n",
    "    \n",
    "    print(\"\\n--- QUERY ---\")\n",
    "    print(query)\n",
    "    \n",
    "    print(\"\\n--- FINAL ANSWER ---\")\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3771fd5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Error while downloading https://capstone-bucket-alister.s3.amazonaws.com/figures/figure_10.png?AWSAccessKeyId=AKIAWQUOZ4236TFSWCUI&Signature=sdsSBvZoovrStBlZSdTw61Oonmg%3D&Expires=1752744629.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      3\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShow me the graph comparing my energy usage to my neighbors and describe it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- QUERY ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(query)\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3046\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3044\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3045\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3046\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3047\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3048\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    374\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    375\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    379\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    380\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    381\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    382\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    383\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    384\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    385\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    386\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    387\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    388\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    961\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    962\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 782\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    783\u001b[0m                 m,\n\u001b[0;32m    784\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    785\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    786\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    787\u001b[0m             )\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1028\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1029\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1030\u001b[0m     )\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:1131\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1087\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1085\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m   1086\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\openai\\_base_client.py:1256\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1244\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1252\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1253\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1254\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1255\u001b[0m     )\n\u001b[1;32m-> 1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Alister\\anaconda3\\envs\\myenv\\lib\\site-packages\\openai\\_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1043\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1044\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Error while downloading https://capstone-bucket-alister.s3.amazonaws.com/figures/figure_10.png?AWSAccessKeyId=AKIAWQUOZ4236TFSWCUI&Signature=sdsSBvZoovrStBlZSdTw61Oonmg%3D&Expires=1752744629.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Show me the graph comparing my energy usage to my neighbors and describe it.\"\n",
    "    answer = chain.invoke(query)\n",
    "    \n",
    "    print(\"\\n--- QUERY ---\")\n",
    "    print(query)\n",
    "    \n",
    "    print(\"\\n--- FINAL ANSWER ---\")\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "63287ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing documents and uploading figures to S3...\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_1.png to S3 with key: figures/figure_1.png\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_2.png to S3 with key: figures/figure_2.png\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_3.png to S3 with key: figures/figure_3.png\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_4.png to S3 with key: figures/figure_4.png\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_5.png to S3 with key: figures/figure_5.png\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_6.png to S3 with key: figures/figure_6.png\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_7.png to S3 with key: figures/figure_7.png\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_8.png to S3 with key: figures/figure_8.png\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_9.png to S3 with key: figures/figure_9.png\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_10.png to S3 with key: figures/figure_10.png\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_11.png to S3 with key: figures/figure_11.png\n",
      "Successfully uploaded output/test_info_extract\\figures/figure_12.png to S3 with key: figures/figure_12.png\n",
      "\n",
      "Retriever setup complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- S3 Upload Function ---\n",
    "def upload_image_to_s3(local_path, bucket_name, s3_client):\n",
    "    \"\"\"\n",
    "    Uploads a local image file to S3 and returns its permanent S3 key.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(local_path):\n",
    "        print(f\"Warning: Image file not found at '{local_path}'.\")\n",
    "        return \"\"\n",
    "    \n",
    "    s3_key = f\"figures/{os.path.basename(local_path)}\"\n",
    "    \n",
    "    try:\n",
    "        s3_client.upload_file(local_path, bucket_name, s3_key)\n",
    "        print(f\"Successfully uploaded {local_path} to S3 with key: {s3_key}\")\n",
    "        return s3_key # Return the key, not the URL\n",
    "    except Exception as e:\n",
    "        print(f\"Error during S3 upload: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# --- 1. Load CSVs and Initialize S3 ---\n",
    "df_full = pd.read_csv(\"output/test_info_extract/layout_with_figures.csv\")\n",
    "df_sum = pd.read_csv(\"output/test_info_extract/layout_with_summaries_2.csv\")\n",
    "assert len(df_full) == len(df_sum), \"Row counts must match\"\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = os.getenv(\"AWS_BUCKET_NAME\")\n",
    "if not bucket_name:\n",
    "    raise ValueError(\"AWS_BUCKET_NAME not set in .env file.\")\n",
    "\n",
    "# --- 2. Build Parent & Child Docs with S3 Keys ---\n",
    "parent_docs, child_docs, ids = [], [], []\n",
    "base_dir = \"output/test_info_extract\"\n",
    "\n",
    "print(\"Processing documents and uploading figures to S3...\")\n",
    "for full, summ in zip(df_full.itertuples(), df_sum.itertuples()):\n",
    "    doc_id = str(uuid.uuid4())\n",
    "    s3_key_str = \"\"\n",
    "\n",
    "    if hasattr(full, 'Layout') and isinstance(full.Layout, str) and full.Layout.startswith(\"Figure\"):\n",
    "        if hasattr(full, 'Text') and pd.notna(full.Text):\n",
    "            relative_image_path = full.Text.replace(\"\\\\\", \"/\")\n",
    "            figure_path = os.path.join(base_dir, relative_image_path)\n",
    "            \n",
    "            # Upload image and get the permanent S3 key\n",
    "            s3_key = upload_image_to_s3(figure_path, bucket_name, s3_client)\n",
    "            \n",
    "            if s3_key:\n",
    "                # Store the key in the document with a clear marker\n",
    "                s3_key_str = f\"\\n[S3_KEY_START]\\n{s3_key}\\n[S3_KEY_END]\"\n",
    "\n",
    "    parent_text_content = summ.Text if \"Figure\" in full.Layout else full.Text\n",
    "    summary_text_content = summ.Text\n",
    "\n",
    "    parent_text = f\"{full.Layout}: {parent_text_content}{s3_key_str}\"\n",
    "    summary_text = f\"{summ.Layout}: {summary_text_content}\"\n",
    "\n",
    "    parent_docs.append(Document(page_content=parent_text, metadata={\"doc_id\": doc_id}))\n",
    "    child_docs.append(Document(page_content=summary_text, metadata={\"doc_id\": doc_id}))\n",
    "    ids.append(doc_id)\n",
    "\n",
    "# --- 3. Setup Retrievers (Unchanged) ---\n",
    "emb = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(collection_name=\"multimodal_rag_s3_on_the_fly\", embedding_function=emb)\n",
    "vectorstore.add_documents(child_docs)\n",
    "\n",
    "bm25 = BM25Retriever.from_documents(child_docs)\n",
    "bm25.k = 5\n",
    "semantic = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "hybrid = EnsembleRetriever(retrievers=[bm25, semantic], weights=[0.5, 0.5])\n",
    "\n",
    "store = InMemoryStore()\n",
    "store.mset(list(zip(ids, parent_docs)))\n",
    "retriever = MultiVectorRetriever(vectorstore=vectorstore, docstore=store, id_key=\"doc_id\")\n",
    "print(\"\\nRetriever setup complete.\")\n",
    "\n",
    "# --- 4. Define the RAG Chain with On-the-Fly URL Generation ---\n",
    "\n",
    "def parse_docs_and_generate_urls(docs):\n",
    "    \"\"\"\n",
    "    Parses retrieved docs for S3 keys and generates fresh pre-signed URLs.\n",
    "    \"\"\"\n",
    "    image_urls = []\n",
    "    text_content = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        parts = doc.page_content.split(\"[S3_KEY_START]\")\n",
    "        text_content.append(parts[0])\n",
    "        \n",
    "        if len(parts) > 1:\n",
    "            s3_key = parts[1].split(\"[S3_KEY_END]\")[0].strip()\n",
    "            # Generate a fresh URL right now\n",
    "            url = s3_client.generate_presigned_url(\n",
    "                'get_object',\n",
    "                Params={'Bucket': bucket_name, 'Key': s3_key},\n",
    "                ExpiresIn=3600 # Valid for 1 hour\n",
    "            )\n",
    "            image_urls.append(url)\n",
    "            \n",
    "    return {\"images\": image_urls, \"texts\": text_content}\n",
    "\n",
    "def build_prompt_with_urls(inputs):\n",
    "    \"\"\"\n",
    "    Dynamically builds the prompt, adding image_url dicts if URLs are present.\n",
    "    \"\"\"\n",
    "    context = inputs[\"context\"]\n",
    "    question = inputs[\"question\"]\n",
    "    \n",
    "    context_text = \"\\n\".join(context['texts']).strip()\n",
    "    \n",
    "    prompt_content = [{\n",
    "        \"type\": \"text\",\n",
    "        \"text\": f\"\"\"Answer the question based only on the following context.\n",
    "\n",
    "Context:\n",
    "---\n",
    "{context_text}\n",
    "---\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "    }]\n",
    "    \n",
    "    for url in context[\"images\"]:\n",
    "        prompt_content.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": url},\n",
    "        })\n",
    "        \n",
    "    return [HumanMessage(content=prompt_content)]\n",
    "\n",
    "# --- Main RAG Chain ---\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(parse_docs_and_generate_urls),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(build_prompt_with_urls)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "41d3da0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- QUERY ---\n",
      "Show me the graph comparing my energy usage to my neighbors and describe it.\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "The first graph is a bar graph comparing energy usage in kilowatt-hours (kWh) among three categories:\n",
      "\n",
      "1. **You**: Represented by a large blue bar indicating a usage of **125 kWh**.\n",
      "2. **Similar nearby homes**: Displayed as an orange bar, showing a usage of **103 kWh**.\n",
      "3. **Efficient nearby homes**: Illustrated with a green bar, demonstrating the lowest usage at **49 kWh**.\n",
      "\n",
      "This graph clearly shows that your energy consumption is **18% higher** than that of similar nearby homes.\n",
      "\n",
      "The second graph is a line graph that tracks electricity usage over several months from April to March among the same three categories:\n",
      "\n",
      "- **You**: Represented by a blue line, showing fluctuating usage levels throughout the months.\n",
      "- **Similar Homes**: Indicated by an orange line, which generally stays above your usage.\n",
      "- **Efficient Homes**: Shown with a green line, consistently indicating the lowest electricity usage.\n",
      "\n",
      "Overall, the line graph illustrates that your electricity consumption varies over the months but remains lower than that of similar homes, while efficient homes consistently use the least energy.\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Show me the graph comparing my energy usage to my neighbors and describe it.\"\n",
    "    answer = chain.invoke(query)\n",
    "    \n",
    "    print(\"\\n--- QUERY ---\")\n",
    "    print(query)\n",
    "    \n",
    "    print(\"\\n--- FINAL ANSWER ---\")\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "17baca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- QUERY ---\n",
      "Give me tips on how to reduce my energy consumption based on the data.\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "Based on the context provided, here are some tips to reduce energy consumption:\n",
      "\n",
      "1. Implement energy-saving practices in the kitchen, such as using energy-efficient appliances and cooking in batches to minimize oven use.\n",
      "2. Optimize laundry practices by washing clothes in cold water and only running full loads to save on electricity.\n",
      "3. Consider other areas of your home where energy can be saved, such as using LED lighting and unplugging devices when not in use.\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Give me tips on how to reduce my energy consumption based on the data.\"\n",
    "    answer = chain.invoke(query)\n",
    "    \n",
    "    print(\"\\n--- QUERY ---\")\n",
    "    print(query)\n",
    "    \n",
    "    print(\"\\n--- FINAL ANSWER ---\")\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9de77ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- QUERY ---\n",
      "For what month is this data?\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "The data is for the month of March.\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"For what month is this data?\"\n",
    "    answer = chain.invoke(query)\n",
    "    \n",
    "    print(\"\\n--- QUERY ---\")\n",
    "    print(query)\n",
    "    \n",
    "    print(\"\\n--- FINAL ANSWER ---\")\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385ca39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce8f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
